{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/anaconda3/envs/dinov2/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/jisu/anaconda3/envs/dinov2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations.core.transforms_interface import DualTransform,ImageOnlyTransform\n",
    "\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import models\n",
    "from collections import OrderedDict\n",
    "from pytorch_model_summary import summary\n",
    "from randaugment import RandAugment\n",
    "from scipy import stats\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torch.nn.utils.spectral_norm import spectral_norm\n",
    "\n",
    "import io\n",
    "import glob\n",
    "import time\n",
    "import zipfile\n",
    "import subprocess\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from contextlib import contextmanager\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce67f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "#train_source, val_source: (2048,1024)\n",
    "#train_target,test : (1920,1080)\n",
    "\n",
    "#class 정보\n",
    "# 0 : Road\n",
    "# 1 : Sidewalk\n",
    "# 2 : Construction\n",
    "# 3 : Fence\n",
    "# 4 : Pole \n",
    "# 5 : Traffic Light\n",
    "# 6 : Traffic Sign\n",
    "# 7 : Nature\n",
    "# 8 : Sky\n",
    "# 9 : Person\n",
    "# 10 : Rider\n",
    "# 11 : Car\n",
    "\n",
    "batch_size = 2\n",
    "f_batch_size = 2\n",
    "epochs = 50\n",
    "F_epochs = 50\n",
    "num_class = 13\n",
    "source_root = './home/js/ssai/open/data/train_source_image'\n",
    "target_root = './home/js/ssai/open/data/train_target_image'\n",
    "learning_rate = 2.5e-2 #2.5e-3\n",
    "iters_per_epoch = 1000\n",
    "seed = 42\n",
    "weight_decay = 0.0005\n",
    "momentum = 0.9\n",
    "train_size = (512,512)\n",
    "test_output_size = (960,540)\n",
    "lr_power = 0.9\n",
    "lr_d =1e-4\n",
    "ignore_label = 255\n",
    "trade_off = 0.01 #0.001 \n",
    "pyramid_weight = 0.5\n",
    "l1_weight = 6\n",
    "\n",
    "palette = [[0, 94, 135], [242, 255, 97], [165, 42, 42], [0, 0, 192],\n",
    "                [197, 226, 255], [0, 60, 100], [0, 0, 142], [62, 200, 71],\n",
    "                [255,207,157], [0, 187, 255], [255, 102, 163],[166,97,247],[0,0,0]]\n",
    "\n",
    "palette = np.array(palette)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8300f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplabv2\n",
    "\n",
    "model_urls = {\n",
    "    'deeplabv2_resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "}\n",
    "\n",
    "#https://discuss.pytorch.org/t/how-to-load-load-state-dict-for-resnet-model/125998/2\n",
    "affine_par = True\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n",
    "        for i in downsample._modules['1'].parameters():\n",
    "            i.requires_grad = False\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)  # change\n",
    "        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "\n",
    "        padding = dilation\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,  # change\n",
    "                               padding=padding, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n",
    "        for i in self.bn2.parameters():\n",
    "            i.requires_grad = False\n",
    "\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n",
    "        for i in self.bn3.parameters():\n",
    "            i.requires_grad = False\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ASPP_V2(nn.Module):\n",
    "    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n",
    "        super(ASPP_V2, self).__init__()\n",
    "        self.conv2d_list = nn.ModuleList()\n",
    "        for dilation, padding in zip(dilation_series, padding_series):\n",
    "            self.conv2d_list.append(\n",
    "                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding, dilation=dilation,\n",
    "                          bias=True))\n",
    "        for m in self.conv2d_list:\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_list[0](x)\n",
    "        for i in range(len(self.conv2d_list) - 1):\n",
    "            out += self.conv2d_list[i + 1](x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Deeplab(nn.Module):\n",
    "    def __init__(self, backbone, classifier, num_classes):\n",
    "        super(Deeplab, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.classifier = classifier\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels=5, out_channels=3, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if  x.size()[1] != 3 :\n",
    "             x = self.conv1(x)\n",
    "        x = self.backbone(x)\n",
    "        y = self.classifier(x)\n",
    "        return y\n",
    "\n",
    "    def get_1x_lr_params_NOscale(self):\n",
    "        \"\"\"\n",
    "        This generator returns all the parameters of the net except for\n",
    "        the last classification layer. Note that for each batchnorm layer,\n",
    "        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
    "        any batchnorm parameter\n",
    "        \"\"\"\n",
    "        # layers = [self.backbone.conv1, self.backbone.bn1,\n",
    "        #         self.backbone.layer1, self.backbone.layer2, self.backbone.layer3, self.backbone.layer4]\n",
    "        layers = [list(self.backbone.children())[0], list(self.backbone.children())[1],\n",
    "                list(self.backbone.children())[4], list(self.backbone.children())[5], \n",
    "                list(self.backbone.children())[6], list(self.backbone.children())[7]]\n",
    "        for layer in layers:\n",
    "            for module in layer.modules():\n",
    "                for param in module.parameters():\n",
    "                    if param.requires_grad:\n",
    "                        yield param\n",
    "\n",
    "    def get_10x_lr_params(self):\n",
    "        \"\"\"\n",
    "        This generator returns all the parameters for the last layer of the net,\n",
    "        which does the classification of pixel into classes\n",
    "        \"\"\"\n",
    "        for param in self.classifier.parameters():\n",
    "            yield param\n",
    "\n",
    "    def get_parameters(self, lr=1.):\n",
    "        return [\n",
    "            {'params': self.get_1x_lr_params_NOscale(), 'lr': 0.1 * lr},\n",
    "            {'params': self.get_10x_lr_params(), 'lr': lr}\n",
    "        ]\n",
    "\n",
    "def deeplabv2_resnet101(num_classes=13, pretrained_backbone=True):\n",
    "    \"\"\"Constructs a DeepLabV2 model with a ResNet-1 01 backbone.\n",
    "\n",
    "     Args:\n",
    "         num_classes (int, optional): number of classes. Default: 19\n",
    "         pretrained_backbone (bool, optional): If True, returns a model pre-trained on ImageNet. Default: True.\n",
    "     \"\"\"\n",
    "    backbone = ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "    if pretrained_backbone:\n",
    "        # download from Internet\n",
    "        #saved_state_dict = load_state_dict_from_url(model_urls['deeplabv2_resnet101'], map_location=lambda storage, loc: storage, file_name=\"deeplabv2_resnet101.pth\")\n",
    "        #pre_backbone= models.resnet101(pretrained=True)\n",
    "        #pre_backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        ckpt = torch.load('./cityscapes_epoch_59.pth')\n",
    "        \n",
    "        # state_dict = ckpt['model']\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in ckpt.items():\n",
    "            if not k.split('.')[1] == 'layer5':\n",
    "                name =  k.replace(\"Scale.\",\"\")\n",
    "                new_state_dict[name] = v\n",
    "            \n",
    "        backbone.load_state_dict(new_state_dict)\n",
    "        #new_params = backbone.state_dict().copy()\n",
    "        # for i in saved_state_dict:\n",
    "        #     i_parts = i.split('.')\n",
    "        #     if not i_parts[1] == 'layer5':\n",
    "        #         new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
    "        # backbone.load_state_dict(new_params)\n",
    "\n",
    "    classifier = ASPP_V2(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n",
    "    return Deeplab(backbone, classifier, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36492b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    r\"\"\"Computes and stores the average and current value.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> # Initialize a meter to record loss\n",
    "        >>> losses = AverageMeter()\n",
    "        >>> # Update meter after every minibatch update\n",
    "        >>> losses.update(loss_value, batch_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, fmt: Optional[str] = ':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        if self.count > 0:\n",
    "            self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class AverageMeterDict(object):\n",
    "    def __init__(self, names: List, fmt: Optional[str] = ':f'):\n",
    "        self.dict = {\n",
    "            name: AverageMeter(name, fmt) for name in names\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        for meter in self.dict.values():\n",
    "            meter.reset()\n",
    "\n",
    "    def update(self, accuracies, n=1):\n",
    "        for name, acc in accuracies.items():\n",
    "            self.dict[name].update(acc, n)\n",
    "\n",
    "    def average(self):\n",
    "        return {\n",
    "            name: meter.avg for name, meter in self.dict.items()\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.dict[item]\n",
    "\n",
    "\n",
    "class Meter(object):\n",
    "    \"\"\"Computes and stores the current value.\"\"\"\n",
    "    def __init__(self, name: str, fmt: Optional[str] = ':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.val = val\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '}'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        #print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b78c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import prettytable\n",
    "\n",
    "__all__ = ['keypoint_detection']\n",
    "\n",
    "def binary_accuracy(output: torch.Tensor, target: torch.Tensor) -> float:\n",
    "    \"\"\"Computes the accuracy for binary classification\"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "        pred = (output >= 0.5).float().t().view(-1)\n",
    "        correct = pred.eq(target.view(-1)).float().sum()\n",
    "        correct.mul_(100. / batch_size)\n",
    "        return correct\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    r\"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified values of k\n",
    "\n",
    "    Args:\n",
    "        output (tensor): Classification outputs, :math:`(N, C)` where `C = number of classes`\n",
    "        target (tensor): :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`\n",
    "        topk (sequence[int]): A list of top-N number.\n",
    "\n",
    "    Returns:\n",
    "        Top-N accuracies (N :math:`\\in` topK).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target[None])\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].flatten().sum(dtype=torch.float32)\n",
    "            res.append(correct_k * (100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "class ConfusionMatrix(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.mat = None\n",
    "\n",
    "    def update(self, target, output):\n",
    "        \"\"\"\n",
    "        Update confusion matrix.\n",
    "\n",
    "        Args:\n",
    "            target: ground truth\n",
    "            output: predictions of models\n",
    "\n",
    "        Shape:\n",
    "            - target: :math:`(minibatch, C)` where C means the number of classes.\n",
    "            - output: :math:`(minibatch, C)` where C means the number of classes.\n",
    "        \"\"\"\n",
    "        n = self.num_classes\n",
    "        if self.mat is None:\n",
    "            self.mat = torch.zeros((n, n), dtype=torch.int64, device=target.device)\n",
    "        with torch.no_grad():\n",
    "            k = (target >= 0) & (target < n)\n",
    "            inds = n * target[k].to(torch.int64) + output[k]\n",
    "            self.mat += torch.bincount(inds, minlength=n**2).reshape(n, n)\n",
    "\n",
    "    def reset(self):\n",
    "        self.mat.zero_()\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"compute global accuracy, per-class accuracy and per-class IoU\"\"\"\n",
    "        h = self.mat.float()\n",
    "        acc_global = torch.diag(h).sum() / h.sum()\n",
    "        acc = torch.diag(h) / h.sum(1)\n",
    "        iu = torch.diag(h) / (h.sum(1) + h.sum(0) - torch.diag(h))\n",
    "        return acc_global, acc, iu\n",
    "\n",
    "    # def reduce_from_all_processes(self):\n",
    "    #     if not torch.distributed.is_available():\n",
    "    #         return\n",
    "    #     if not torch.distributed.is_initialized():\n",
    "    #         return\n",
    "    #     torch.distributed.barrier()\n",
    "    #     torch.distributed.all_reduce(self.mat)\n",
    "\n",
    "    def __str__(self):\n",
    "        acc_global, acc, iu = self.compute()\n",
    "        return (\n",
    "            'global correct: {:.1f}\\n'\n",
    "            'average row correct: {}\\n'\n",
    "            'IoU: {}\\n'\n",
    "            'mean IoU: {:.1f}').format(\n",
    "                acc_global.item() * 100,\n",
    "                ['{:.1f}'.format(i) for i in (acc * 100).tolist()],\n",
    "                ['{:.1f}'.format(i) for i in (iu * 100).tolist()],\n",
    "                iu.mean().item() * 100)\n",
    "\n",
    "    def format(self, classes: list):\n",
    "        \"\"\"Get the accuracy and IoU for each class in the table format\"\"\"\n",
    "        acc_global, acc, iu = self.compute()\n",
    "\n",
    "        table = prettytable.PrettyTable([\"class\", \"acc\", \"iou\"])\n",
    "        for i, class_name, per_acc, per_iu in zip(range(len(classes)), classes, (acc * 100).tolist(), (iu * 100).tolist()):\n",
    "            table.add_row([class_name, per_acc, per_iu])\n",
    "\n",
    "        return 'global correct: {:.1f}\\nmean correct:{:.1f}\\nmean IoU: {:.1f}\\n{}'.format(\n",
    "            acc_global.item() * 100, acc.mean().item() * 100, iu.mean().item() * 100, table.get_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1913427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_device(tensor, device):\n",
    "    \"\"\"\n",
    "    Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device.\n",
    "\n",
    "    Args:\n",
    "        tensor (nested list/tuple/dictionary of :obj:`torch.Tensor`):\n",
    "            The data to send to a given device.\n",
    "        device (:obj:`torch.device`):\n",
    "            The device to send the data to\n",
    "\n",
    "    Returns:\n",
    "        The same data structure as :obj:`tensor` with all tensors sent to the proper device.\n",
    "    \"\"\"\n",
    "    if isinstance(tensor, (list, tuple)):\n",
    "        return type(tensor)(send_to_device(t, device) for t in tensor)\n",
    "    elif isinstance(tensor, dict):\n",
    "        return type(tensor)({k: send_to_device(v, device) for k, v in tensor.items()})\n",
    "    elif not hasattr(tensor, \"to\"):\n",
    "        return tensor\n",
    "    return tensor.to(device)\n",
    "\n",
    "\n",
    "class ForeverDataIterator:\n",
    "    r\"\"\"A data iterator that will never stop producing data\"\"\"\n",
    "\n",
    "    def __init__(self, data_loader: DataLoader, device=None):\n",
    "        self.data_loader = data_loader\n",
    "        self.iter = iter(self.data_loader)\n",
    "        self.device = device\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            data = next(self.iter)\n",
    "            if self.device is not None:\n",
    "                data = send_to_device(data, self.device)\n",
    "        except StopIteration:\n",
    "            self.iter = iter(self.data_loader)\n",
    "            data = next(self.iter)\n",
    "            if self.device is not None:\n",
    "                data = send_to_device(data, self.device)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb905bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxSquareloss(nn.Module):\n",
    "    def __init__(self, ignore_index= -1, num_class=13):\n",
    "        super().__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.num_class = num_class\n",
    "    \n",
    "    def forward(self, pred, prob):\n",
    "        \"\"\"\n",
    "        :param pred: predictions (N, C, H, W)\n",
    "        :param prob: probability of pred (N, C, H, W)\n",
    "        :return: maximum squares loss\n",
    "        \"\"\"\n",
    "        # prob -= 0.5\n",
    "        mask = (prob != self.ignore_index)    \n",
    "        loss = -torch.mean(torch.pow(prob, 2)[mask]) / 2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77087aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "\n",
    "def train(train_source_iter: ForeverDataIterator, train_target_iter: ForeverDataIterator,\n",
    "          model, interp, criterion, dann, flownet,\n",
    "          optimizer: SGD, lr_scheduler: LambdaLR, optimizer_d: SGD, lr_scheduler_d: LambdaLR,\n",
    "          epoch: int):\n",
    "    \n",
    "    losses_s = AverageMeter('Loss (s)', ':3.2f')\n",
    "    losses_transfer = AverageMeter('Loss (transfer)', ':3.2f')\n",
    "    losses_discriminator = AverageMeter('Loss (discriminator)', ':3.2f')\n",
    "    accuracies_s = Meter('Acc (s)', ':3.2f')\n",
    "    accuracies_t = Meter('Acc (t)', ':3.2f')\n",
    "    iou_s = Meter('IoU (s)', ':3.2f')\n",
    "    iou_t = Meter('IoU (t)', ':3.2f')\n",
    "\n",
    "    confmat_s = ConfusionMatrix(num_class)\n",
    "    #confmat_t = ConfusionMatrix(model.num_classes)\n",
    "\n",
    "    model.train()\n",
    "    flownet.eval()\n",
    "    for i in range(iters_per_epoch):\n",
    "        if(i % 100 == 0):\n",
    "            print(\"iters : \",i)\n",
    "        iter_start = time.time()\n",
    "        x_s, label_s = next(train_source_iter)\n",
    "        x_t = next(train_target_iter)\n",
    "\n",
    "        x_s = x_s.to(device)\n",
    "        label_s = label_s.long().to(device)\n",
    "\n",
    "        x_t = x_t.to(device)\n",
    "        #label_t = label_t.long().to(device)\n",
    "        \n",
    "        _,_,target_flow_map = flownet(x_t)\n",
    "        \n",
    "        # print(x_t.shape)\n",
    "        # print(target_flow_map.shape)\n",
    "        \n",
    "        x_t_flow = torch.concat((x_t,target_flow_map),dim=1)\n",
    "        # print(x_t_flow.shape)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # # Step 1: Train the segmentation network, freeze the discriminator\n",
    "        dann.eval() #DomainAdversarialEntropyLoss\n",
    "        y_s = model(x_s)\n",
    "        pred_s = interp(y_s)\n",
    "        #segmentaiton : cross-entropy loss (generator 즉 segmentataion network 학습)\n",
    "        loss_cls_s = criterion(pred_s, label_s.squeeze(1))\n",
    "        loss_cls_s.backward()\n",
    "\n",
    "        # adversarial training to fool the discriminator\n",
    "\n",
    "        y_t = model(x_t_flow) # 똑같이 segmentation network에 target image를 넣고\n",
    "        pred_t = interp(y_t)\n",
    "        loss_transfer = dann(pred_t, 'source') # target image의 prediction 값을\n",
    "        (loss_transfer * trade_off).backward()\n",
    "\n",
    "        # Step 2: Train the discriminator\n",
    "        dann.train()\n",
    "        loss_discriminator = 0.5 * (dann(pred_s.detach(), 'source') + dann(pred_t.detach(), 'target'))\n",
    "        loss_discriminator.backward()\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.step()\n",
    "        optimizer_d.step()\n",
    "        lr_scheduler.step()\n",
    "        lr_scheduler_d.step()\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses_s.update(loss_cls_s.item(), x_s.size(0))\n",
    "        losses_transfer.update(loss_transfer.item(), x_s.size(0))\n",
    "        losses_discriminator.update(loss_discriminator.item(), x_s.size(0))\n",
    "\n",
    "        confmat_s.update(label_s.flatten(), pred_s.argmax(1).flatten())\n",
    "        #confmat_t.update(label_t.flatten(), pred_t.argmax(1).flatten())\n",
    "        acc_global_s, acc_s, iu_s = confmat_s.compute()\n",
    "        #acc_global_t, acc_t, iu_t = confmat_t.compute()\n",
    "        accuracies_s.update(acc_s.mean().item())\n",
    "        #accuracies_t.update(acc_t.mean().item())\n",
    "        iou_s.update(iu_s.mean().item())\n",
    "\n",
    "        iter_end = time.time()\n",
    "        if(i % 100 == 0):\n",
    "            print(\"seg_loss : \", loss_cls_s.item())\n",
    "            print(\"entropy_loss: \",loss_transfer.item())\n",
    "            print(\"disc_loss : \", loss_discriminator.item())\n",
    "            print(\"iter end, time : \", iter_end-iter_start)\n",
    "        #iou_t.update(iu_t.mean().item())\n",
    "\n",
    "        # if i % args.print_freq == 0:\n",
    "        #     progress.display(i)\n",
    "\n",
    "        #     if visualize is not None:\n",
    "        #         visualize(x_s[0], pred_s[0], label_s[0], \"source_{}\".format(i))\n",
    "        #         visualize(x_t[0], pred_t[0], label_t[0], \"target_{}\".format(i))\n",
    "\n",
    "def validate(val_loader: DataLoader, model, interp, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    acc = Meter('Acc', ':3.2f')\n",
    "    iou = Meter('IoU', ':3.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, acc, iou],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    confmat = ConfusionMatrix(num_class)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, label) in enumerate(val_loader):\n",
    "            x = x.to(device)\n",
    "            label = label.long().to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = interp(model(x))\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            losses.update(loss.item(), x.size(0))\n",
    "            confmat.update(label.flatten(), output.argmax(1).flatten())\n",
    "            acc_global, accs, iu = confmat.compute()\n",
    "            acc.update(accs.mean().item())\n",
    "            iou.update(iu.mean().item())\n",
    "\n",
    "            # if i % args.print_freq == 0:\n",
    "            #     progress.display(i)\n",
    "\n",
    "            #     if visualize is not None:\n",
    "            #         visualize(x[0], output[0], label[0], \"val_{}\".format(i))\n",
    "\n",
    "    return confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91de5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False, source=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        self.source = source\n",
    "        self.classes = ['Road','Sidewalk','Construction','Fence','Pole','Traffic Light'\n",
    "                        ,'Traffic Sign','Nature','Sky','Person','Rider','Car','Background']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        if self.source==True:\n",
    "            mask_path = self.data.iloc[idx, 2]\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "            if self.transform:\n",
    "            \n",
    "                augmented = self.transform(image=image, mask=mask)\n",
    "                image = augmented['image']\n",
    "                mask = augmented['mask']\n",
    "\n",
    "                #transform 확인용\n",
    "                \n",
    "                # mask = palette[mask]\n",
    "                # name = img_path.split('/')[-1]\n",
    "                # cv2.imwrite(f'./trans/{name}.png', image)\n",
    "                # cv2.imwrite(f'./trans/mask_{name}.png', mask)\n",
    "            return image, mask\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030e0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fisheye augmentation \n",
    "\n",
    "scale = 5.5\n",
    "def fisheye_distortion_rm(image):\n",
    "    \n",
    "    h,w = image.shape[:2]\n",
    "\n",
    "    focal_length = w / 4\n",
    "    center_x = w / 2 \n",
    "    center_y = h / 2\n",
    "    camera_matrix = np.array([[focal_length,0,center_x],[0,focal_length,center_y],[0,0,1]],dtype=np.float32)\n",
    "\n",
    "    dist_coeffs = np.array([0,0.5,0,0],dtype=np.float32)\n",
    "    map_x, map_y = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, None, (w, h), cv2.CV_32FC1)\n",
    "    undistorted_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    uh,uw = undistorted_image.shape[:2]\n",
    "\n",
    "    # min_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][0]\n",
    "    # max_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][-1]\n",
    "    # min_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][0]\n",
    "    # max_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][-1]\n",
    "\n",
    "    # undistorted_image = undistorted_image[min_y:max_y,min_x:max_x]\n",
    "\n",
    "    undistorted_image = undistorted_image[int(h/scale):int(h-h/scale),int(w/scale):int(w-w/scale)]\n",
    "\n",
    "    return undistorted_image\n",
    "\n",
    "def fisheye_distortion_mask_rm(image):\n",
    "    #image[image==0] = 255\n",
    "    h,w = image.shape[:2]\n",
    "\n",
    "    focal_length = w / 4\n",
    "    center_x = w / 2 \n",
    "    center_y = h / 2\n",
    "    camera_matrix = np.array([[focal_length,0,center_x],[0,focal_length,center_y],[0,0,1]],dtype=np.float32)\n",
    "\n",
    "    dist_coeffs = np.array([0,0.5,0,0],dtype=np.float32)\n",
    "\n",
    "    map_x, map_y = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, None, (w, h), cv2.CV_32FC1)\n",
    "    undistorted_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT,borderValue=12)\n",
    "\n",
    "\n",
    "    uh,uw = undistorted_image.shape[:2]\n",
    "\n",
    "    # min_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][0]\n",
    "    # max_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][-1]\n",
    "    # min_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][0]\n",
    "    # max_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][-1]\n",
    "\n",
    "    undistorted_image = undistorted_image[int(h/scale):int(h-h/scale),int(w/scale):int(w-w/scale)].astype(np.uint8)\n",
    "    #undistorted_image = undistorted_image[coord[0]:coord[1],coord[2]:coord[3]].astype(np.uint8)\n",
    "\n",
    "    return undistorted_image\n",
    "\n",
    "class Fisheye(DualTransform):\n",
    "    def __init__(self):\n",
    "        super(Fisheye,self).__init__()\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        return fisheye_distortion_rm(img)\n",
    "\n",
    "    def apply_to_mask(self, mask, **params):\n",
    "        return fisheye_distortion_mask_rm(mask)\n",
    "    \n",
    "# def fisheye_distortion(image):\n",
    "    \n",
    "#     h,w = image.shape[:2]\n",
    "\n",
    "#     focal_length = w / 4\n",
    "#     center_x = w / 2 \n",
    "#     center_y = h / 2\n",
    "#     camera_matrix = np.array([[focal_length,0,center_x],[0,focal_length,center_y],[0,0,1]],dtype=np.float32)\n",
    "\n",
    "#     dist_coeffs = np.array([0,0.5,0,0],dtype=np.uint8)\n",
    "\n",
    "#     undistorted_image = cv2.undistort(image,camera_matrix,dist_coeffs)\n",
    "#     #undistorted_image = undistorted_image[h//5:h-h//5,w//5:w-w//5]\n",
    "\n",
    "#     return undistorted_image\n",
    "\n",
    "# def fisheye_distortion_mask(image):\n",
    "#     image[image==0] = 255\n",
    "#     h,w = image.shape[:2]\n",
    "\n",
    "#     focal_length = w / 4\n",
    "#     center_x = w / 2 \n",
    "#     center_y = h / 2\n",
    "#     camera_matrix = np.array([[focal_length,0,center_x],[0,focal_length,center_y],[0,0,1]],dtype=np.float32)\n",
    "\n",
    "#     dist_coeffs = np.array([0,0.5,0,0],dtype=np.float32)\n",
    "\n",
    "#     undistorted_image = cv2.undistort(image,camera_matrix,dist_coeffs)\n",
    "#     #undistorted_image = undistorted_image[h//5:h-h//5,w//5:w-w//5].astype(np.uint8)\n",
    "#     #undistorted_image = np.round(undistorted_image).astype(np.uint8)\n",
    "#     undistorted_image[undistorted_image==0] = 12\n",
    "#     #undistorted_image = filter(undistorted_image)\n",
    "#     undistorted_image[undistorted_image>12] = 0\n",
    "\n",
    "#     return undistorted_image\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc4adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2_entropy(prob):\n",
    "    \"\"\" convert probabilistic prediction maps to weighted self-information maps\n",
    "    \"\"\"\n",
    "    n, c, h, w = prob.size()\n",
    "    return -torch.mul(prob, torch.log2(prob + 1e-30)) / np.log2(c)\n",
    "\n",
    "\n",
    "def bce_loss(y_pred, y_label):\n",
    "    y_truth_tensor = torch.FloatTensor(y_pred.size())\n",
    "    y_truth_tensor.fill_(y_label)\n",
    "    y_truth_tensor = y_truth_tensor.to(y_pred.get_device())\n",
    "    return F.binary_cross_entropy_with_logits(y_pred, y_truth_tensor)\n",
    "\n",
    "class Discriminator(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Domain discriminator model from\n",
    "    `ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation (CVPR 2019) <https://arxiv.org/abs/1811.12833>`_\n",
    "\n",
    "    Distinguish pixel-by-pixel whether the input predictions come from the source domain or the target domain.\n",
    "    The source domain label is 1 and the target domain label is 0.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): num of classes in the predictions\n",
    "        ndf (int): dimension of the hidden features\n",
    "\n",
    "    Shape:\n",
    "        - Inputs: :math:`(minibatch, C, H, W)` where :math:`C` is the number of classes\n",
    "        - Outputs: :math:`(minibatch, 1, H, W)`\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, ndf=64):\n",
    "        super(Discriminator, self).__init__(\n",
    "            nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "class DomainAdversarialEntropyLoss(nn.Module):\n",
    "    r\"\"\"The `Domain Adversarial Entropy Loss <https://arxiv.org/abs/1811.12833>`_\n",
    "\n",
    "    Minimizing entropy with adversarial learning through training a domain discriminator.\n",
    "\n",
    "    Args:\n",
    "        domain_discriminator (torch.nn.Module): A domain discriminator object, which predicts\n",
    "          the domains of predictions. Its input shape is :math:`(minibatch, C, H, W)` and output shape is :math:`(minibatch, 1, H, W)`\n",
    "\n",
    "    Inputs:\n",
    "        - logits (tensor): logits output of segmentation model\n",
    "        - domain_label (str, optional): whether the data comes from source or target.\n",
    "          Choices: ['source', 'target']. Default: 'source'\n",
    "\n",
    "    Shape:\n",
    "        - logits: :math:`(minibatch, C, H, W)` where :math:`C` means the number of classes\n",
    "        - Outputs: scalar.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> B, C, H, W = 2, 19, 512, 512\n",
    "        >>> discriminator = Discriminator(num_classes=C)\n",
    "        >>> dann = DomainAdversarialEntropyLoss(discriminator)\n",
    "        >>> # logits output on source domain and target domain\n",
    "        >>> y_s, y_t = torch.randn(B, C, H, W), torch.randn(B, C, H, W)\n",
    "        >>> loss = 0.5 * (dann(y_s, \"source\") + dann(y_t, \"target\"))\n",
    "    \"\"\"\n",
    "    def __init__(self, discriminator: nn.Module):\n",
    "        super(DomainAdversarialEntropyLoss, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.entropy = None\n",
    "\n",
    "    def forward(self, logits, domain_label='source'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert domain_label in ['source', 'target']\n",
    "        probability = F.softmax(logits, dim=1) \n",
    "        entropy = prob_2_entropy(probability)\n",
    "        self.entropy = entropy\n",
    "        domain_prediciton = self.discriminator(entropy)\n",
    "        if domain_label == 'source':\n",
    "            return bce_loss(domain_prediciton, 1)\n",
    "        else:\n",
    "            return bce_loss(domain_prediciton, 0)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        r\"\"\"Sets the discriminator in training mode. In the training mode,\n",
    "        all the parameters in discriminator will be set requires_grad=True.\n",
    "\n",
    "        Args:\n",
    "            mode (bool): whether to set training mode (``True``) or evaluation mode (``False``). Default: ``True``.\n",
    "        \"\"\"\n",
    "        self.discriminator.train(mode)\n",
    "        for param in self.discriminator.parameters():\n",
    "            param.requires_grad = mode\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        r\"\"\"Sets the module in evaluation mode. In the training mode,\n",
    "        all the parameters in discriminator will be set requires_grad=False.\n",
    "\n",
    "        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
    "        \"\"\"\n",
    "        return self.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea401ec4",
   "metadata": {},
   "source": [
    "## FlowNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a53fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_spectral_norm(module, use_sn=False):\n",
    "    if use_sn:\n",
    "        return spectral_norm(module)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbd30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter to gpu or cpu\n",
    "def set_device(args):\n",
    "  if torch.cuda.is_available():\n",
    "    if isinstance(args, list):\n",
    "      return (item.cuda() for item in args)\n",
    "    else:\n",
    "      return args.cuda()\n",
    "  return args\n",
    "\n",
    "def postprocess(img):\n",
    "  img = (img+1)/2*255\n",
    "  img = img.permute(0,2,3,1)\n",
    "  img = img.int().cpu().numpy().astype(np.uint8)\n",
    "  return img\n",
    "\n",
    "\n",
    "class Progbar(object):\n",
    "  \"\"\"Displays a progress bar.\n",
    "\n",
    "  Arguments:\n",
    "    target: Total number of steps expected, None if unknown.\n",
    "    width: Progress bar width on screen.\n",
    "    verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n",
    "    stateful_metrics: Iterable of string names of metrics that\n",
    "      should *not* be averaged over time. Metrics in this list\n",
    "      will be displayed as-is. All others will be averaged\n",
    "      by the progbar before display.\n",
    "    interval: Minimum visual progress update interval (in seconds).\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, target, width=25, verbose=1, interval=0.05, stateful_metrics=None):\n",
    "    self.target = target\n",
    "    self.width = width\n",
    "    self.verbose = verbose\n",
    "    self.interval = interval\n",
    "    if stateful_metrics:\n",
    "      self.stateful_metrics = set(stateful_metrics)\n",
    "    else:\n",
    "      self.stateful_metrics = set()\n",
    "\n",
    "    self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n",
    "      sys.stdout.isatty()) or 'ipykernel' in sys.modules or 'posix' in sys.modules)\n",
    "    self._total_width = 0\n",
    "    self._seen_so_far = 0\n",
    "    # We use a dict + list to avoid garbage collection\n",
    "    # issues found in OrderedDict\n",
    "    self._values = {}\n",
    "    self._values_order = []\n",
    "    self._start = time.time()\n",
    "    self._last_update = 0\n",
    "\n",
    "  def update(self, current, values=None):\n",
    "    \"\"\"Updates the progress bar.\n",
    "    Arguments:\n",
    "      current: Index of current step.\n",
    "      values: List of tuples:\n",
    "        `(name, value_for_last_step)`.\n",
    "        If `name` is in `stateful_metrics`,\n",
    "        `value_for_last_step` will be displayed as-is.\n",
    "        Else, an average of the metric over time will be displayed.\n",
    "    \"\"\"\n",
    "    values = values or []\n",
    "    for k, v in values:\n",
    "      if k not in self._values_order:\n",
    "        self._values_order.append(k)\n",
    "      if k not in self.stateful_metrics:\n",
    "        if k not in self._values:\n",
    "          self._values[k] = [v * (current - self._seen_so_far), current - self._seen_so_far]\n",
    "        else:\n",
    "          self._values[k][0] += v * (current - self._seen_so_far)\n",
    "          self._values[k][1] += (current - self._seen_so_far)\n",
    "      else:\n",
    "        self._values[k] = v\n",
    "    self._seen_so_far = current\n",
    "\n",
    "    now = time.time()\n",
    "    info = ' - %.0fs' % (now - self._start)\n",
    "    if self.verbose == 1:\n",
    "      if (now - self._last_update < self.interval and \n",
    "        self.target is not None and current < self.target):\n",
    "          return\n",
    "\n",
    "      prev_total_width = self._total_width\n",
    "      if self._dynamic_display:\n",
    "        sys.stdout.write('\\b' * prev_total_width)\n",
    "        sys.stdout.write('\\r')\n",
    "      else:\n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "      if self.target is not None:\n",
    "        numdigits = int(np.floor(np.log10(self.target))) + 1\n",
    "        barstr = '%%%dd/%d [' % (numdigits, self.target)\n",
    "        bar = barstr % current\n",
    "        prog = float(current) / self.target\n",
    "        prog_width = int(self.width * prog)\n",
    "        if prog_width > 0:\n",
    "          bar += ('=' * (prog_width - 1))\n",
    "          if current < self.target:\n",
    "            bar += '>'\n",
    "          else:\n",
    "            bar += '='\n",
    "        bar += ('.' * (self.width - prog_width))\n",
    "        bar += ']'\n",
    "      else:\n",
    "        bar = '%7d/Unknown' % current\n",
    "      self._total_width = len(bar)\n",
    "      sys.stdout.write(bar)\n",
    "      if current:\n",
    "        time_per_unit = (now - self._start) / current\n",
    "      else:\n",
    "        time_per_unit = 0\n",
    "      if self.target is not None and current < self.target:\n",
    "        eta = time_per_unit * (self.target - current)\n",
    "        if eta > 3600:\n",
    "          eta_format = '%d:%02d:%02d' % (eta // 3600, (eta % 3600) // 60, eta % 60)\n",
    "        elif eta > 60:\n",
    "          eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
    "        else:\n",
    "          eta_format = '%ds' % eta\n",
    "        info = ' - ETA: %s' % eta_format\n",
    "      else:\n",
    "        if time_per_unit >= 1:\n",
    "          info += ' %.0fs/step' % time_per_unit\n",
    "        elif time_per_unit >= 1e-3:\n",
    "          info += ' %.0fms/step' % (time_per_unit * 1e3)\n",
    "        else:\n",
    "          info += ' %.0fus/step' % (time_per_unit * 1e6)\n",
    "\n",
    "      for k in self._values_order:\n",
    "        info += ' - %s:' % k\n",
    "        if isinstance(self._values[k], list):\n",
    "          avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
    "          if abs(avg) > 1e-3:\n",
    "            info += ' %.4f' % avg\n",
    "          else:\n",
    "            info += ' %.4e' % avg\n",
    "        else:\n",
    "          info += ' %s' % self._values[k]\n",
    "\n",
    "      self._total_width += len(info)\n",
    "      if prev_total_width > self._total_width:\n",
    "        info += (' ' * (prev_total_width - self._total_width))\n",
    "      if self.target is not None and current >= self.target:\n",
    "        info += '\\n'\n",
    "      sys.stdout.write(info)\n",
    "      sys.stdout.flush()\n",
    "    elif self.verbose == 2:\n",
    "      if self.target is None or current >= self.target:\n",
    "        for k in self._values_order:\n",
    "          info += ' - %s:' % k\n",
    "          avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
    "          if avg > 1e-3:\n",
    "            info += ' %.4f' % avg\n",
    "          else:\n",
    "            info += ' %.4e' % avg\n",
    "        info += '\\n'\n",
    "        sys.stdout.write(info)\n",
    "        sys.stdout.flush()\n",
    "    self._last_update = now\n",
    "\n",
    "  def add(self, n, values=None):\n",
    "    self.update(self._seen_so_far + n, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2caa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False, source=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        self.source = source\n",
    "        self.classes = ['Road','Sidewalk','Construction','Fence','Pole','Traffic Light'\n",
    "                        ,'Traffic Sign','Nature','Sky','Person','Rider','Car','Background']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = image\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "            #transform 확인용\n",
    "            # name = img_path.split('/')[-1]\n",
    "            # cv2.imwrite(f'./trans/{name}.png', image)\n",
    "            # cv2.imwrite(f'./trans/mask_{name}.png', mask)\n",
    "            \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc0be65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fisheye_distortion_rm(image):\n",
    "\n",
    "    h,w = image.shape[:2]\n",
    "\n",
    "    fl_rand = random.randint(2,6)\n",
    "    focal_length = w / fl_rand\n",
    "\n",
    "    center_x = w / 2 \n",
    "    center_y = h / 2\n",
    "    camera_matrix = np.array([[focal_length,0,center_x],[0,focal_length,center_y],[0,0,1]],dtype=np.float32)\n",
    "\n",
    "    rand_dist = np.random.rand(1)[0]\n",
    "    dist_coeffs = np.array([0,rand_dist,0,0],dtype=np.float32)\n",
    "\n",
    "    map_x, map_y = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, None, (w, h), cv2.CV_32FC1)\n",
    "    undistorted_image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "\n",
    "    uh,uw = undistorted_image.shape[:2]\n",
    "\n",
    "\n",
    "    min_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][0]\n",
    "    max_x = np.where((undistorted_image[uh//2][:][:]!=0))[0][-1]\n",
    "    min_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][0]\n",
    "    max_y = np.where((undistorted_image[:,uw//2,:]!=0))[0][-1]\n",
    "\n",
    "    undistorted_image = undistorted_image[min_y:max_y,min_x:max_x]\n",
    "    \n",
    "    return undistorted_image\n",
    "\n",
    "def random_fisheye_distortion_mask_rm(image):\n",
    "    return image\n",
    "\n",
    "class RandomFisheye(DualTransform):\n",
    "    def __init__(self):\n",
    "        super(RandomFisheye,self).__init__()\n",
    "    \n",
    "    def apply(self, img, **params):\n",
    "        return random_fisheye_distortion_rm(img)\n",
    "    \n",
    "    def apply_to_mask(self, mask, **params):\n",
    "        return random_fisheye_distortion_mask_rm(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe0e7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate(shape, det_uv):\n",
    "    b, _, w, h = shape\n",
    "    uv_d = np.zeros([w, h, 2], np.float32)\n",
    "\n",
    "    for i in range(0, w):\n",
    "        for j in range(0, h):\n",
    "            uv_d[i, j, 0] = j\n",
    "            uv_d[i, j, 1] = i\n",
    "\n",
    "    uv_d = np.expand_dims(uv_d.swapaxes(2, 1).swapaxes(1, 0), 0)     # 1 2 w h\n",
    "    uv_d = torch.from_numpy(uv_d).cuda()\n",
    "    uv_d = uv_d.repeat(b, 1, 1, 1)\n",
    "\n",
    "    det_uv = uv_d + det_uv                                            # b 2 w h\n",
    "\n",
    "    return det_uv\n",
    "\n",
    "def uniform(shape, fish_uv):\n",
    "    b, _, w, h = shape\n",
    "    x0 = (w - 1) / 2. \n",
    "\n",
    "    fish_nor = (fish_uv - x0)/x0             # b 2 w h\n",
    "    fish_nor = fish_nor.permute(0, 2, 3, 1)  # b w h 2\n",
    "    return fish_nor\n",
    "\n",
    "def resample_image(feature, flow):\n",
    "    fish_uv = get_coordinate(feature.shape, flow)\n",
    "    grid = uniform(feature.shape, fish_uv)\n",
    "    target_image = F.grid_sample(feature, grid)\n",
    "    return target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e8360e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_image(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation='tanh'):\n",
    "        super(Get_image, self).__init__()\n",
    "        self.conv = Conv2dBlock(input_dim, output_dim, kernel_size=3, stride=1,\n",
    "                     padding=1, pad_type='reflect', activation=activation)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResBlocks(nn.Module):\n",
    "    def __init__(self, num_blocks, dim, norm='in', activation='relu', pad_type='zero', use_sn=False):\n",
    "        super(ResBlocks, self).__init__()\n",
    "        self.model = []\n",
    "        for i in range(num_blocks):\n",
    "            self.model += [ResBlock(dim, norm=norm, activation=activation, pad_type=pad_type, use_sn=use_sn)]\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim, norm='in', activation='relu', pad_type='zero', use_sn=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        model = []\n",
    "        model += [Conv2dBlock(dim ,dim, 3, 1, 1, norm=norm, activation=activation, pad_type=pad_type, use_sn=use_sn)]\n",
    "        model += [Conv2dBlock(dim ,dim, 3, 1, 1, norm=norm, activation='none', pad_type=pad_type, use_sn=use_sn)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.model(x)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class DilationBlock(nn.Module):\n",
    "    def __init__(self, dim, norm='in', activation='relu', pad_type='zero'):\n",
    "        super(DilationBlock, self).__init__()\n",
    "\n",
    "        model = []\n",
    "        model += [Conv2dBlock(dim ,dim, 3, 1, 2, norm=norm, activation=activation, pad_type=pad_type, dilation=2)]\n",
    "        model += [Conv2dBlock(dim ,dim, 3, 1, 4, norm=norm, activation=activation, pad_type=pad_type, dilation=4)]\n",
    "        model += [Conv2dBlock(dim ,dim, 3, 1, 8, norm=norm, activation=activation, pad_type=pad_type, dilation=8)]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, input_dim ,output_dim, kernel_size, stride,\n",
    "                 padding=0, norm='none', activation='relu', pad_type='zero', dilation=1,\n",
    "                 use_bias=True, use_sn=False):\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        self.use_bias = use_bias\n",
    "        # initialize padding\n",
    "        if pad_type == 'reflect':\n",
    "            self.pad = nn.ReflectionPad2d(padding)\n",
    "        elif pad_type == 'replicate':\n",
    "            self.pad = nn.ReplicationPad2d(padding)\n",
    "        elif pad_type == 'zero':\n",
    "            self.pad = nn.ZeroPad2d(padding)\n",
    "        else:\n",
    "            assert 0, \"Unsupported padding type: {}\".format(pad_type)\n",
    "\n",
    "        # initialize normalization\n",
    "        norm_dim = output_dim\n",
    "        if norm == 'bn':\n",
    "            self.norm = nn.BatchNorm2d(norm_dim)\n",
    "        elif norm == 'in':\n",
    "            self.norm = nn.InstanceNorm2d(norm_dim)\n",
    "        elif norm == 'ln':\n",
    "            self.norm = LayerNorm(norm_dim)\n",
    "        elif norm == 'adain':\n",
    "            self.norm = AdaptiveInstanceNorm2d(norm_dim)\n",
    "        elif norm == 'none':\n",
    "            self.norm = None\n",
    "        else:\n",
    "            assert 0, \"Unsupported normalization: {}\".format(norm)\n",
    "\n",
    "        # initialize activation\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "        elif activation == 'lrelu':\n",
    "            self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif activation == 'prelu':\n",
    "            self.activation = nn.PReLU()\n",
    "        elif activation == 'selu':\n",
    "            self.activation = nn.SELU(inplace=True)\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'none':\n",
    "            self.activation = None\n",
    "        else:\n",
    "            assert 0, \"Unsupported activation: {}\".format(activation)\n",
    "\n",
    "        # initialize convolution\n",
    "        if use_sn:\n",
    "            self.conv = spectral_norm(nn.Conv2d(input_dim, output_dim, kernel_size, stride, bias=self.use_bias, dilation=dilation))\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride, bias=self.use_bias, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.pad(x))\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class TransConv2dBlock(nn.Module):\n",
    "    def __init__(self, input_dim ,output_dim, kernel_size, stride,\n",
    "                 padding=0, norm='none', activation='relu'):\n",
    "        super(TransConv2dBlock, self).__init__()\n",
    "        self.use_bias = True\n",
    "\n",
    "        # initialize normalization\n",
    "        norm_dim = output_dim\n",
    "        if norm == 'bn':\n",
    "            self.norm = nn.BatchNorm2d(norm_dim)\n",
    "        elif norm == 'in':\n",
    "            self.norm = nn.InstanceNorm2d(norm_dim)\n",
    "        elif norm == 'in_affine':\n",
    "            self.norm = nn.InstanceNorm2d(norm_dim, affine=True)\n",
    "        elif norm == 'ln':\n",
    "            self.norm = LayerNorm(norm_dim)\n",
    "        elif norm == 'adain':\n",
    "            self.norm = AdaptiveInstanceNorm2d(norm_dim)\n",
    "        elif norm == 'none':\n",
    "            self.norm = None\n",
    "        else:\n",
    "            assert 0, \"Unsupported normalization: {}\".format(norm)\n",
    "\n",
    "        # initialize activation\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "        elif activation == 'lrelu':\n",
    "            self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif activation == 'prelu':\n",
    "            self.activation = nn.PReLU()\n",
    "        elif activation == 'selu':\n",
    "            self.activation = nn.SELU(inplace=True)\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == 'none':\n",
    "            self.activation = None\n",
    "        else:\n",
    "            assert 0, \"Unsupported activation: {}\".format(activation)\n",
    "\n",
    "        # initialize convolution\n",
    "        self.transConv = nn.ConvTranspose2d(input_dim, output_dim, kernel_size, stride, padding, bias=self.use_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transConv(x)\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class AdaptiveInstanceNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(AdaptiveInstanceNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        # weight and bias are dynamically assigned\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        # just dummy buffers, not used\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.weight is not None and self.bias is not None, \"Please assign weight and bias before calling AdaIN!\"\n",
    "        b, c = x.size(0), x.size(1)\n",
    "        running_mean = self.running_mean.repeat(b)\n",
    "        running_var = self.running_var.repeat(b)\n",
    "\n",
    "        # Apply instance norm\n",
    "        x_reshaped = x.contiguous().view(1, b * c, *x.size()[2:])\n",
    "\n",
    "        out = F.batch_norm(\n",
    "            x_reshaped, running_mean, running_var, self.weight, self.bias,\n",
    "            True, self.momentum, self.eps)\n",
    "\n",
    "        return out.view(b, c, *x.size()[2:])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + str(self.num_features) + ')'\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, n_out, eps=1e-5, affine=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.n_out = n_out\n",
    "        self.affine = affine\n",
    "\n",
    "        if self.affine:\n",
    "          self.weight = nn.Parameter(torch.ones(n_out, 1, 1))\n",
    "          self.bias = nn.Parameter(torch.zeros(n_out, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        normalized_shape = x.size()[1:]\n",
    "        if self.affine:\n",
    "          return F.layer_norm(x, normalized_shape, self.weight.expand(normalized_shape), self.bias.expand(normalized_shape))\n",
    "        else:\n",
    "          return F.layer_norm(x, normalized_shape)\n",
    "\n",
    "class DownsampleResBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, norm='in', activation='relu', pad_type='zero', use_sn=False):\n",
    "        super(DownsampleResBlock, self).__init__()\n",
    "        self.conv_1 = nn.ModuleList()\n",
    "        self.conv_2 = nn.ModuleList()\n",
    "\n",
    "        self.conv_1.append(Conv2dBlock(input_dim,input_dim,3,1,1,'none',activation,pad_type,use_sn=use_sn))\n",
    "        self.conv_1.append(Conv2dBlock(input_dim,output_dim,3,1,1,'none',activation,pad_type,use_sn=use_sn))\n",
    "        self.conv_1.append(nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.conv_1 = nn.Sequential(*self.conv_1)\n",
    "\n",
    "\n",
    "        self.conv_2.append(nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "        self.conv_2.append(Conv2dBlock(input_dim,output_dim,1,1,0,'none',activation,pad_type,use_sn=use_sn))\n",
    "        self.conv_2 = nn.Sequential(*self.conv_2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x) + self.conv_2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd92a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BaseNetwork, self).__init__()\n",
    "\n",
    "  def print_network(self):\n",
    "    if isinstance(self, list):\n",
    "      self = self[0]\n",
    "    num_params = 0\n",
    "    for param in self.parameters():\n",
    "      num_params += param.numel()\n",
    "    print('Network [%s] was created. Total number of parameters: %.1f million. '\n",
    "          'To see the architecture, do print(network).'% (type(self).__name__, num_params / 1000000))\n",
    "\n",
    "  def init_weights(self, init_type='normal', gain=0.02):\n",
    "    '''\n",
    "    initialize network's weights\n",
    "    init_type: normal | xavier | kaiming | orthogonal\n",
    "    https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n",
    "    '''\n",
    "    def init_func(m):\n",
    "      classname = m.__class__.__name__\n",
    "      if classname.find('InstanceNorm2d') != -1:\n",
    "        if hasattr(m, 'weight') and m.weight is not None:\n",
    "          nn.init.constant_(m.weight.data, 1.0)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0.0)\n",
    "      elif hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "        if init_type == 'normal':\n",
    "          nn.init.normal_(m.weight.data, 0.0, gain)\n",
    "        elif init_type == 'xavier':\n",
    "          nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "        elif init_type == 'xavier_uniform':\n",
    "          nn.init.xavier_uniform_(m.weight.data, gain=1.0)\n",
    "        elif init_type == 'kaiming':\n",
    "          nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        elif init_type == 'orthogonal':\n",
    "          nn.init.orthogonal_(m.weight.data, gain=gain)\n",
    "        elif init_type == 'none':  # uses pytorch's default init method\n",
    "          m.reset_parameters()\n",
    "        else:\n",
    "          raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    self.apply(init_func)\n",
    "\n",
    "    # propagate to children\n",
    "    for m in self.children():\n",
    "      if hasattr(m, 'init_weights'):\n",
    "        m.init_weights(init_type, gain)\n",
    "\n",
    "class InpaintGenerator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(InpaintGenerator, self).__init__()\n",
    "\n",
    "    self.flow_column = FlowColumn()\n",
    "    self.conv_column = InpaintNet()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "      flow_map, flows = self.flow_column(inputs)\n",
    "      pyramid_imgs, images_out = self.conv_column(inputs, flows)\n",
    "      return pyramid_imgs, images_out,flow_map\n",
    "\n",
    "class InpaintNet(BaseNetwork):\n",
    "  def __init__(self, init_weights=True):\n",
    "    super(InpaintNet, self).__init__()\n",
    "\n",
    "    cnum = 32\n",
    "\n",
    "    self.dw_conv01 = nn.Sequential(\n",
    "        nn.Conv2d(3, cnum, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True))\n",
    "    self.dw_conv02 = nn.Sequential(\n",
    "        nn.Conv2d(cnum, cnum * 2, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True))\n",
    "    self.dw_conv03 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 2, cnum * 4, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True))\n",
    "    self.dw_conv04 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 4, cnum * 8, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True))\n",
    "    self.dw_conv05 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 8, cnum * 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True))\n",
    "    self.dw_conv06 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 16, cnum * 16, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "    self.up_conv05 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 16, cnum * 16, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "    self.up_conv04 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 32, cnum * 8, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "    self.up_conv03 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 16, cnum * 4, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "    self.up_conv02 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 8, cnum * 2, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "    self.up_conv01 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 4, cnum * 1, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 2, cnum, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(cnum, 3, kernel_size=3, stride=1, padding=1),\n",
    "        nn.Tanh())\n",
    "\n",
    "    self.torgb5 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 32, 3, kernel_size=1, stride=1, padding=0),\n",
    "        nn.Tanh())\n",
    "    self.torgb4 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 16, 3, kernel_size=1, stride=1, padding=0),\n",
    "        nn.Tanh())\n",
    "    self.torgb3 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 8, 3, kernel_size=1, stride=1, padding=0),\n",
    "        nn.Tanh())\n",
    "    self.torgb2 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 4, 3, kernel_size=1, stride=1, padding=0),\n",
    "        nn.Tanh())\n",
    "    self.torgb1 = nn.Sequential(\n",
    "        nn.Conv2d(cnum * 2, 3, kernel_size=1, stride=1, padding=0),\n",
    "        nn.Tanh())\n",
    "\n",
    "    if init_weights:\n",
    "        self.init_weights()\n",
    "\n",
    "  def forward(self, img, flows):\n",
    "      x = img\n",
    "\n",
    "      x1 = self.dw_conv01(x)\n",
    "      x2 = self.dw_conv02(x1)\n",
    "      x3 = self.dw_conv03(x2)\n",
    "      x4 = self.dw_conv04(x3)\n",
    "      x5 = self.dw_conv05(x4)\n",
    "      x6 = self.dw_conv06(x5)\n",
    "\n",
    "      x5 = resample_image(x5, flows[4])\n",
    "      x4 = resample_image(x4, flows[3])\n",
    "      x3 = resample_image(x3, flows[2])\n",
    "      x2 = resample_image(x2, flows[1])\n",
    "      x1 = resample_image(x1, flows[0])\n",
    "\n",
    "      upx5 = self.up_conv05(F.interpolate(x6, scale_factor=2, mode='bilinear', align_corners=True))\n",
    "      upx4 = self.up_conv04(\n",
    "          F.interpolate(torch.cat([upx5, x5], dim=1), scale_factor=2, mode='bilinear', align_corners=True))\n",
    "      upx3 = self.up_conv03(\n",
    "          F.interpolate(torch.cat([upx4, x4], dim=1), scale_factor=2, mode='bilinear', align_corners=True))\n",
    "      upx2 = self.up_conv02(\n",
    "          F.interpolate(torch.cat([upx3, x3], dim=1), scale_factor=2, mode='bilinear', align_corners=True))\n",
    "      upx1 = self.up_conv01(\n",
    "          F.interpolate(torch.cat([upx2, x2], dim=1), scale_factor=2, mode='bilinear', align_corners=True))\n",
    "\n",
    "      img5 = self.torgb5(torch.cat([upx5, x5], dim=1))\n",
    "      img4 = self.torgb4(torch.cat([upx4, x4], dim=1))\n",
    "      img3 = self.torgb3(torch.cat([upx3, x3], dim=1))\n",
    "      img2 = self.torgb2(torch.cat([upx2, x2], dim=1))\n",
    "      img1 = self.torgb1(torch.cat([upx1, x1], dim=1))\n",
    "\n",
    "      output = self.decoder(\n",
    "          F.interpolate(torch.cat([upx1, x1], dim=1), scale_factor=2, mode='bilinear', align_corners=True))\n",
    "      pyramid_imgs = [img1, img2, img3, img4, img5]\n",
    "      return pyramid_imgs, output\n",
    "\n",
    "class FlowColumn(nn.Module):\n",
    "    def __init__(self, input_dim=3, dim=64, n_res=2, activ='lrelu',\n",
    "                 norm='in', pad_type='reflect', use_sn=True):\n",
    "        super(FlowColumn, self).__init__()\n",
    "\n",
    "        self.down_flow01 = nn.Sequential(\n",
    "            Conv2dBlock(input_dim, dim // 2, 7, 1, 3, norm, activ, pad_type, use_sn=use_sn),\n",
    "            Conv2dBlock(dim // 2, dim // 2, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "        self.down_flow02 = nn.Sequential(\n",
    "            Conv2dBlock(dim // 2, dim // 2, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "        self.down_flow03 = nn.Sequential(\n",
    "            Conv2dBlock(dim // 2, dim, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "        self.down_flow04 = nn.Sequential(\n",
    "            Conv2dBlock(dim, 2 * dim, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "        self.down_flow05 = nn.Sequential(\n",
    "            Conv2dBlock(2 * dim, 4 * dim, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "        self.down_flow06 = nn.Sequential(\n",
    "            Conv2dBlock(4 * dim, 8 * dim, 4, 2, 1, norm, activ, pad_type, use_sn=use_sn))\n",
    "\n",
    "        dim = 8 * dim\n",
    "\n",
    "        self.up_flow05 = nn.Sequential(\n",
    "            ResBlocks(n_res, dim, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim, dim // 2, 6, 2, 2, norm=norm, activation=activ))\n",
    "\n",
    "        self.up_flow04 = nn.Sequential(\n",
    "            Conv2dBlock(dim, dim // 2, 5, 1, 2, norm, activ, pad_type, use_sn=use_sn),\n",
    "            ResBlocks(n_res, dim // 2, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim // 2, dim // 4, 6, 2, 2, norm=norm, activation=activ))\n",
    "\n",
    "        self.up_flow03 = nn.Sequential(\n",
    "            Conv2dBlock(dim // 2, dim // 4, 5, 1, 2, norm, activ, pad_type, use_sn=use_sn),\n",
    "            ResBlocks(n_res, dim // 4, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim // 4, dim // 8, 6, 2, 2, norm=norm, activation=activ))\n",
    "\n",
    "        self.up_flow02 = nn.Sequential(\n",
    "            Conv2dBlock(dim // 4, dim // 8, 5, 1, 2, norm, activ, pad_type, use_sn=use_sn),\n",
    "            ResBlocks(n_res, dim // 8, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim // 8, dim // 16, 6, 2, 2, norm=norm, activation=activ))\n",
    "\n",
    "        self.up_flow01 = nn.Sequential(\n",
    "            Conv2dBlock(dim // 8, dim // 16, 5, 1, 2, norm, activ, pad_type, use_sn=use_sn),\n",
    "            ResBlocks(n_res, dim // 16, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim // 16, dim // 16, 6, 2, 2, norm=norm, activation=activ))\n",
    "\n",
    "        self.location = nn.Sequential(\n",
    "            Conv2dBlock(dim // 8, dim // 16, 5, 1, 2, norm, activ, pad_type, use_sn=use_sn),\n",
    "            ResBlocks(n_res, dim // 16, norm, activ, pad_type=pad_type),\n",
    "            TransConv2dBlock(dim // 16, dim // 16, 6, 2, 2, norm=norm, activation=activ),\n",
    "            Conv2dBlock(dim // 16, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False))\n",
    "\n",
    "        self.to_flow05 = Conv2dBlock(dim // 2, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False)\n",
    "        self.to_flow04 = Conv2dBlock(dim // 4, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False)\n",
    "        self.to_flow03 = Conv2dBlock(dim // 8, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False)\n",
    "        self.to_flow02 = Conv2dBlock(dim // 16, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False)\n",
    "        self.to_flow01 = Conv2dBlock(dim // 16, 2, 3, 1, 1, norm='none', activation='none', pad_type=pad_type, use_bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        f_x1 = self.down_flow01(inputs)\n",
    "        f_x2 = self.down_flow02(f_x1)\n",
    "        f_x3 = self.down_flow03(f_x2)\n",
    "        f_x4 = self.down_flow04(f_x3)\n",
    "        f_x5 = self.down_flow05(f_x4)\n",
    "        f_x6 = self.down_flow06(f_x5)\n",
    "\n",
    "        f_u5 = self.up_flow05(f_x6)\n",
    "        f_u4 = self.up_flow04(torch.cat((f_u5, f_x5), 1))\n",
    "        f_u3 = self.up_flow03(torch.cat((f_u4, f_x4), 1))\n",
    "        f_u2 = self.up_flow02(torch.cat((f_u3, f_x3), 1))\n",
    "        f_u1 = self.up_flow01(torch.cat((f_u2, f_x2), 1))\n",
    "        flow_map = self.location(torch.cat((f_u1, f_x1), 1))\n",
    "\n",
    "        flow05 = self.to_flow05(f_u5)\n",
    "        flow04 = self.to_flow04(f_u4)\n",
    "        flow03 = self.to_flow03(f_u3)\n",
    "        flow02 = self.to_flow02(f_u2)\n",
    "        flow01 = self.to_flow01(f_u1)\n",
    "\n",
    "        return flow_map, [flow01, flow02, flow03, flow04, flow05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "712302f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flownet train\n",
    "\n",
    "def main():\n",
    "    transform = A.Compose(\n",
    "    [   \n",
    "        A.OneOf([RandomFisheye()],p=1),\n",
    "        A.Resize(train_size[1], train_size[0]),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    # Data loading code\n",
    "    train_dataset = CustomDataset(csv_file='./train_source.csv', transform=transform, source=True)\n",
    "\n",
    "    train_source_loader = DataLoader(train_dataset, batch_size=f_batch_size,\n",
    "                                     shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "\n",
    "    flownet = InpaintGenerator().to(device)\n",
    "    l1_loss = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(flownet.parameters(), lr=1e-4,betas=(0.5, 0.999))\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda F_epoch : 0.95**F_epoch )\n",
    "    best_mae = 9999\n",
    "    \n",
    "    #print(summary(flownet,torch.zeros(1,3,512,512).to(device),max_depth=None,show_parent_layers=True,show_input=True))\n",
    "\n",
    "    for F_epoch in range(F_epochs):\n",
    "        print(\"current epoch : \", F_epoch)\n",
    "        start_time = time.time()\n",
    "        epoch_loss = 0\n",
    "        mae = 0\n",
    "        for images, gt in tqdm(train_source_loader):\n",
    "\n",
    "            images, gt = set_device([images, gt])\n",
    "            gt = gt.permute(0,3,1,2).type(torch.DoubleTensor).to(device)\n",
    "            feats, pred_img,flow_map = flownet(images)\n",
    "            comp_img = pred_img\n",
    "\n",
    "            #reconstruction loss\n",
    "            L1_loss = l1_loss(comp_img, gt) * l1_weight\n",
    "\n",
    "            if feats is not None:\n",
    "                pyramid_loss = 0\n",
    "                for _, f in enumerate(feats):\n",
    "                    #print(f)\n",
    "                    pyramid_loss += l1_loss(f, F.interpolate(gt, size=f.size()[2:4], mode='bilinear',\n",
    "                                                                  align_corners=True))\n",
    "                pyramid_loss += pyramid_loss * pyramid_weight\n",
    "\n",
    "            flow_loss = L1_loss+pyramid_loss\n",
    "        \n",
    "            # generator backward\n",
    "            optimizer.zero_grad()\n",
    "            flow_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += flow_loss.item()\n",
    "\n",
    "        print(f'Epoch {F_epoch}, Loss: {epoch_loss/len(train_source_loader)}')\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        new_mae = (torch.mean(torch.abs(gt - pred_img))).item()\n",
    "        mae = new_mae\n",
    "        print(\"flow_loss : \", flow_loss.item())\n",
    "        if mae < best_mae :\n",
    "            torch.save({\n",
    "            'model': flownet.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'epoch': F_epoch,\n",
    "            }, f'./flow_save_path/flow_save_{F_epoch}.pth' )\n",
    "            print(\"save_model / mae : \", mae)\n",
    "            best_mae = mae\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"epoch_time : \", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "543fb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f26bb3",
   "metadata": {},
   "source": [
    "## ADVENT train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdf94082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(resume=None):\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    transform = A.Compose(\n",
    "    [   \n",
    "        Fisheye(),\n",
    "        A.Resize(train_size[1], train_size[0]),\n",
    "        A.augmentations.geometric.transforms.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    # Data loading code\n",
    "    source_dataset = CustomDataset(csv_file='./train_source.csv', transform=transform, source=True)\n",
    "\n",
    "    train_source_loader = DataLoader(source_dataset, batch_size=batch_size,\n",
    "                                     shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "\n",
    "    target_dataset = CustomDataset(csv_file='./train_target.csv', transform=transform, source=False)\n",
    "    train_target_loader = DataLoader(target_dataset, batch_size=batch_size,\n",
    "                                     shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "    \n",
    "    val_target_dataset = CustomDataset(csv_file='./val_source.csv', transform=transform)\n",
    "    val_target_loader = DataLoader(val_target_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "    train_source_iter = ForeverDataIterator(train_source_loader)\n",
    "    train_target_iter = ForeverDataIterator(train_target_loader)\n",
    "\n",
    "    # create model\n",
    "    num_classes = num_class\n",
    "    model = deeplabv2_resnet101(num_classes=num_classes).to(device)\n",
    "    discriminator = Discriminator(num_classes=num_classes).to(device)\n",
    "    flownet = InpaintGenerator().to(device)\n",
    "    flow_path = './flow_save_path/flow_save_27.pth'\n",
    "    flow_ckpt = torch.load(flow_path, map_location='cpu')\n",
    "    flownet.load_state_dict(flow_ckpt['model'])\n",
    "    flownet.eval()\n",
    "    \n",
    "    # define optimizer and lr scheduler\n",
    "    optimizer = SGD(model.get_parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    optimizer_d = Adam(discriminator.parameters(), lr=lr_d, betas=(0.9, 0.99))\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda x: learning_rate * (1. - float(x) / epochs / iters_per_epoch) ** (lr_power))\n",
    "    lr_scheduler_d = LambdaLR(optimizer_d, lambda x: (1. - float(x) / epochs / iters_per_epoch) ** (lr_power))\n",
    "\n",
    "    #optionally resume from a checkpoint\n",
    "    if resume:\n",
    "        checkpoint = torch.load(resume, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        optimizer_d.load_state_dict(checkpoint['optimizer_d'])\n",
    "        lr_scheduler_d.load_state_dict(checkpoint['lr_scheduler_d'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "    else:\n",
    "        start_epoch =0\n",
    "    # define loss function (criterion)\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=ignore_label).to(device) # segmentation loss\n",
    "    dann = DomainAdversarialEntropyLoss(discriminator) # adversarial loss \n",
    "    interp_train = nn.Upsample(size=train_size[::-1], mode='bilinear', align_corners=True)\n",
    "    interp_val = nn.Upsample(size=test_output_size[::-1], mode='bilinear', align_corners=True)\n",
    "\n",
    "\n",
    "    # define visualization function\n",
    "    #decode = source_dataset.decode_target\n",
    "\n",
    "    # def visualize(image, pred, label, prefix):\n",
    "    #     \"\"\"\n",
    "    #     Args:\n",
    "    #         image (tensor): 3 x H x W\n",
    "    #         pred (tensor): C x H x W\n",
    "    #         label (tensor): H x W\n",
    "    #         prefix: prefix of the saving image\n",
    "    #     \"\"\"\n",
    "    #     image = image.detach().cpu().numpy()\n",
    "    #     pred = pred.detach().max(dim=0)[1].cpu().numpy()\n",
    "    #     label = label.cpu().numpy()\n",
    "    #     for tensor, name in [TypeError: 'int' object is not callable\n",
    "    #         (Image.fromarray(np.uint8(DeNormalizeAndTranspose()(image))), \"image\"),\n",
    "    #         (decode(label), \"label\"),\n",
    "    #         (decode(pred), \"pred\")\n",
    "    #     ]:\n",
    "    #         tensor.save(logger.get_image_path(\"{}_{}.png\".format(prefix, name)))\n",
    "\n",
    "    # if args.phase == 'test':\n",
    "    #     confmat = validate(val_target_loader, model, interp_val, criterion, visualize, args)\n",
    "    #     print(confmat)\n",
    "    #     return\n",
    "\n",
    "    # start training\n",
    "    best_iou = 0.\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(\"current epoch :\", epoch)\n",
    "        print(lr_scheduler.get_lr(), lr_scheduler_d.get_lr())\n",
    "        # train for one epoch\n",
    "        print(\"train start\")\n",
    "        train_start = time.time()\n",
    "        train(train_source_iter, train_target_iter, model, interp_train, criterion, dann,flownet, optimizer,\n",
    "              lr_scheduler, optimizer_d, lr_scheduler_d, epoch)\n",
    "        train_end = time.time()\n",
    "        print(\"train end\")\n",
    "        print(\"epoch_time : \", train_end-train_start)\n",
    "        # evaluate on validation set\n",
    "        confmat = validate(val_target_loader, model, interp_train, criterion)\n",
    "        print(confmat.format(source_dataset.classes))\n",
    "        acc_global, acc, iu = confmat.compute()\n",
    "\n",
    "        # calculate the mean iou over partial classes\n",
    "        indexes = [source_dataset.classes.index(name) for name\n",
    "                   in source_dataset.classes]\n",
    "        iu = iu[indexes]\n",
    "        mean_iou = iu.mean()\n",
    "\n",
    "        #remember best acc@1 and save checkpoint\n",
    "        if mean_iou > best_iou:\n",
    "            torch.save(\n",
    "            {\n",
    "                'model': model.state_dict(),\n",
    "                'discriminator': discriminator.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'optimizer_d': optimizer_d.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'lr_scheduler_d': lr_scheduler_d.state_dict(),\n",
    "                'epoch': epoch,\n",
    "            }, f'./save_path/model_save_v2_flow_{epoch}.pth' )\n",
    "        \n",
    "    \n",
    "            #shutil.copy(logger.get_checkpoint_path(epoch), logger.get_checkpoint_path('best'))\n",
    "        best_iou = max(best_iou, mean_iou)\n",
    "        print(\"Target: {} Best: {}\".format(mean_iou, best_iou))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99018b2",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c11f26fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/optim/sgd.py:27: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch : 20\n",
      "[0.0015786146687233882, 0.015786146687233882] [6.314458674893553e-05]\n",
      "train start\n",
      "iters :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jisu/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/home/jisu/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_loss :  0.13430733978748322\n",
      "entropy_loss:  1.5470466613769531\n",
      "disc_loss :  0.4074442982673645\n",
      "iter end, time :  7.900942802429199\n",
      "iters :  100\n",
      "seg_loss :  0.10852577537298203\n",
      "entropy_loss:  1.5860178470611572\n",
      "disc_loss :  0.546929121017456\n",
      "iter end, time :  1.0153617858886719\n",
      "iters :  200\n",
      "seg_loss :  0.13114376366138458\n",
      "entropy_loss:  1.3395910263061523\n",
      "disc_loss :  0.43961653113365173\n",
      "iter end, time :  1.0197322368621826\n",
      "iters :  300\n",
      "seg_loss :  0.07959704101085663\n",
      "entropy_loss:  1.087096929550171\n",
      "disc_loss :  0.5469233989715576\n",
      "iter end, time :  1.0167593955993652\n",
      "iters :  400\n",
      "seg_loss :  0.11285069584846497\n",
      "entropy_loss:  1.2388653755187988\n",
      "disc_loss :  0.5443356037139893\n",
      "iter end, time :  0.9651339054107666\n",
      "iters :  500\n",
      "seg_loss :  0.1507871448993683\n",
      "entropy_loss:  1.4134207963943481\n",
      "disc_loss :  0.6279618740081787\n",
      "iter end, time :  1.0077173709869385\n",
      "iters :  600\n",
      "seg_loss :  0.16402029991149902\n",
      "entropy_loss:  1.1789054870605469\n",
      "disc_loss :  0.5853868722915649\n",
      "iter end, time :  0.9940645694732666\n",
      "iters :  700\n",
      "seg_loss :  0.11818748712539673\n",
      "entropy_loss:  0.9170253276824951\n",
      "disc_loss :  0.5764144659042358\n",
      "iter end, time :  1.0057570934295654\n",
      "iters :  800\n",
      "seg_loss :  0.12562179565429688\n",
      "entropy_loss:  1.2611631155014038\n",
      "disc_loss :  0.4507800340652466\n",
      "iter end, time :  1.0009922981262207\n",
      "iters :  900\n",
      "seg_loss :  0.07927527278661728\n",
      "entropy_loss:  1.293864130973816\n",
      "disc_loss :  0.5376181602478027\n",
      "iter end, time :  0.9679880142211914\n",
      "train end\n",
      "epoch_time :  1003.7780721187592\n",
      "global correct: 90.9\n",
      "mean correct:56.1\n",
      "mean IoU: 50.9\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 89.91770935058594  | 85.79930114746094  |\n",
      "|    Sidewalk   | 36.89246368408203  | 33.09109878540039  |\n",
      "|  Construction |  89.5567626953125  | 72.48294830322266  |\n",
      "|     Fence     | 26.55852508544922  | 22.923561096191406 |\n",
      "|      Pole     | 17.25658416748047  | 15.398581504821777 |\n",
      "| Traffic Light | 32.765377044677734 | 28.505292892456055 |\n",
      "|  Traffic Sign | 51.788414001464844 | 46.52533721923828  |\n",
      "|     Nature    | 89.03948211669922  | 80.90017700195312  |\n",
      "|      Sky      | 97.79058837890625  |  93.9087905883789  |\n",
      "|     Person    | 1.7315623760223389 | 1.7023433446884155 |\n",
      "|     Rider     | 7.981220722198486  | 4.761904716491699  |\n",
      "|      Car      | 89.70209503173828  | 81.63117980957031  |\n",
      "|   Background  | 98.14823150634766  | 93.55472564697266  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5086040496826172 Best: 0.5086040496826172\n",
      "current epoch : 21\n",
      "[0.0015311763159798313, 0.015311763159798313] [6.124705263919325e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.07216161489486694\n",
      "entropy_loss:  1.4455513954162598\n",
      "disc_loss :  0.5447585582733154\n",
      "iter end, time :  1.0111572742462158\n",
      "iters :  100\n",
      "seg_loss :  0.11187861859798431\n",
      "entropy_loss:  1.3355493545532227\n",
      "disc_loss :  0.7136939764022827\n",
      "iter end, time :  0.9635658264160156\n",
      "iters :  200\n",
      "seg_loss :  0.16839461028575897\n",
      "entropy_loss:  1.2421257495880127\n",
      "disc_loss :  0.595373272895813\n",
      "iter end, time :  1.0105023384094238\n",
      "iters :  300\n",
      "seg_loss :  0.131026953458786\n",
      "entropy_loss:  0.9437961578369141\n",
      "disc_loss :  0.5966901183128357\n",
      "iter end, time :  0.9900662899017334\n",
      "iters :  400\n",
      "seg_loss :  0.08906581252813339\n",
      "entropy_loss:  1.0157842636108398\n",
      "disc_loss :  0.4560058116912842\n",
      "iter end, time :  0.9987576007843018\n",
      "iters :  500\n",
      "seg_loss :  0.10785207897424698\n",
      "entropy_loss:  1.3959763050079346\n",
      "disc_loss :  0.48069238662719727\n",
      "iter end, time :  1.0115656852722168\n",
      "iters :  600\n",
      "seg_loss :  0.09124988317489624\n",
      "entropy_loss:  0.9368879795074463\n",
      "disc_loss :  0.6239409446716309\n",
      "iter end, time :  0.960991621017456\n",
      "iters :  700\n",
      "seg_loss :  0.15082719922065735\n",
      "entropy_loss:  0.9662573337554932\n",
      "disc_loss :  0.566378116607666\n",
      "iter end, time :  0.9652080535888672\n",
      "iters :  800\n",
      "seg_loss :  0.23018568754196167\n",
      "entropy_loss:  1.2767457962036133\n",
      "disc_loss :  0.5142537951469421\n",
      "iter end, time :  0.9577560424804688\n",
      "iters :  900\n",
      "seg_loss :  0.11709810793399811\n",
      "entropy_loss:  1.3688712120056152\n",
      "disc_loss :  0.5473780632019043\n",
      "iter end, time :  1.0046703815460205\n",
      "train end\n",
      "epoch_time :  993.0272099971771\n",
      "global correct: 90.6\n",
      "mean correct:60.2\n",
      "mean IoU: 52.3\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 88.28570556640625  | 85.15013885498047  |\n",
      "|    Sidewalk   | 48.98697280883789  | 41.071720123291016 |\n",
      "|  Construction | 88.43262481689453  | 74.05121612548828  |\n",
      "|     Fence     | 38.89160919189453  | 30.614444732666016 |\n",
      "|      Pole     | 23.258777618408203 | 18.75376319885254  |\n",
      "| Traffic Light | 35.33293151855469  | 21.88323974609375  |\n",
      "|  Traffic Sign | 54.10930633544922  | 46.830692291259766 |\n",
      "|     Nature    |  91.1440200805664  | 81.69344329833984  |\n",
      "|      Sky      |  95.4598617553711  | 92.69288635253906  |\n",
      "|     Person    | 4.227730751037598  | 4.0846052169799805 |\n",
      "|     Rider     | 25.090253829956055 | 11.012517929077148 |\n",
      "|      Car      | 89.93280792236328  | 81.53506469726562  |\n",
      "|   Background  | 98.87748718261719  | 90.01751708984375  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5226086378097534 Best: 0.5226086378097534\n",
      "current epoch : 22\n",
      "[0.001483574066176465, 0.01483574066176465] [5.93429626470586e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.1799084097146988\n",
      "entropy_loss:  1.277022361755371\n",
      "disc_loss :  0.41531237959861755\n",
      "iter end, time :  0.9937360286712646\n",
      "iters :  100\n",
      "seg_loss :  0.10403311252593994\n",
      "entropy_loss:  1.2478861808776855\n",
      "disc_loss :  0.5136957764625549\n",
      "iter end, time :  1.015401840209961\n",
      "iters :  200\n",
      "seg_loss :  0.1177552193403244\n",
      "entropy_loss:  1.0132629871368408\n",
      "disc_loss :  0.5454938411712646\n",
      "iter end, time :  1.002129077911377\n",
      "iters :  300\n",
      "seg_loss :  0.07015342265367508\n",
      "entropy_loss:  1.2953197956085205\n",
      "disc_loss :  0.390521764755249\n",
      "iter end, time :  0.9666788578033447\n",
      "iters :  400\n",
      "seg_loss :  0.10456549376249313\n",
      "entropy_loss:  1.1136915683746338\n",
      "disc_loss :  0.4954543113708496\n",
      "iter end, time :  1.012000560760498\n",
      "iters :  500\n",
      "seg_loss :  0.14658842980861664\n",
      "entropy_loss:  1.0115411281585693\n",
      "disc_loss :  0.5159616470336914\n",
      "iter end, time :  1.0003323554992676\n",
      "iters :  600\n",
      "seg_loss :  0.11144279688596725\n",
      "entropy_loss:  1.0540854930877686\n",
      "disc_loss :  0.5189640522003174\n",
      "iter end, time :  1.0007147789001465\n",
      "iters :  700\n",
      "seg_loss :  0.2027226686477661\n",
      "entropy_loss:  0.8245395421981812\n",
      "disc_loss :  0.7130253314971924\n",
      "iter end, time :  1.0036027431488037\n",
      "iters :  800\n",
      "seg_loss :  0.08353306353092194\n",
      "entropy_loss:  1.1602528095245361\n",
      "disc_loss :  0.567206859588623\n",
      "iter end, time :  0.9630813598632812\n",
      "iters :  900\n",
      "seg_loss :  0.0962592363357544\n",
      "entropy_loss:  1.0563461780548096\n",
      "disc_loss :  0.6231212615966797\n",
      "iter end, time :  0.9623005390167236\n",
      "train end\n",
      "epoch_time :  996.6847794055939\n",
      "global correct: 91.1\n",
      "mean correct:56.6\n",
      "mean IoU: 51.3\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     |  89.4669418334961  |  85.6849365234375  |\n",
      "|    Sidewalk   | 29.172393798828125 | 27.602481842041016 |\n",
      "|  Construction | 91.24790954589844  | 73.27013397216797  |\n",
      "|     Fence     | 39.330936431884766 | 31.343597412109375 |\n",
      "|      Pole     | 14.447543144226074 | 13.231372833251953 |\n",
      "| Traffic Light | 30.261098861694336 | 26.680124282836914 |\n",
      "|  Traffic Sign | 52.61171340942383  | 46.88917922973633  |\n",
      "|     Nature    | 86.98129272460938  | 80.66478729248047  |\n",
      "|      Sky      | 97.74215698242188  | 94.48985290527344  |\n",
      "|     Person    | 4.866055488586426  | 4.631464004516602  |\n",
      "|     Rider     | 11.797950744628906 | 6.420607089996338  |\n",
      "|      Car      | 88.75822448730469  |  81.8883285522461  |\n",
      "|   Background  | 98.71490478515625  | 93.64514923095703  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5126477479934692 Best: 0.5226086378097534\n",
      "current epoch : 23\n",
      "[0.0014358014662863355, 0.014358014662863353] [5.743205865145341e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.06499303877353668\n",
      "entropy_loss:  1.197171926498413\n",
      "disc_loss :  0.5638559460639954\n",
      "iter end, time :  0.9526879787445068\n",
      "iters :  100\n",
      "seg_loss :  0.13144969940185547\n",
      "entropy_loss:  0.9449298977851868\n",
      "disc_loss :  0.575715184211731\n",
      "iter end, time :  0.958033561706543\n",
      "iters :  200\n",
      "seg_loss :  0.07814322412014008\n",
      "entropy_loss:  1.1387141942977905\n",
      "disc_loss :  0.5720278024673462\n",
      "iter end, time :  1.002596378326416\n",
      "iters :  300\n",
      "seg_loss :  0.10738539695739746\n",
      "entropy_loss:  1.3325965404510498\n",
      "disc_loss :  0.4644385576248169\n",
      "iter end, time :  0.9862711429595947\n",
      "iters :  400\n",
      "seg_loss :  0.06722869724035263\n",
      "entropy_loss:  1.3419467210769653\n",
      "disc_loss :  0.46277374029159546\n",
      "iter end, time :  0.9971859455108643\n",
      "iters :  500\n",
      "seg_loss :  0.15251439809799194\n",
      "entropy_loss:  1.127204418182373\n",
      "disc_loss :  0.5528913736343384\n",
      "iter end, time :  0.9770548343658447\n",
      "iters :  600\n",
      "seg_loss :  0.14924198389053345\n",
      "entropy_loss:  0.9493638277053833\n",
      "disc_loss :  0.6048932075500488\n",
      "iter end, time :  1.0115156173706055\n",
      "iters :  700\n",
      "seg_loss :  0.09264080226421356\n",
      "entropy_loss:  1.1221357583999634\n",
      "disc_loss :  0.5046341419219971\n",
      "iter end, time :  1.0015158653259277\n",
      "iters :  800\n",
      "seg_loss :  0.10776210576295853\n",
      "entropy_loss:  1.16395902633667\n",
      "disc_loss :  0.542298436164856\n",
      "iter end, time :  1.015770673751831\n",
      "iters :  900\n",
      "seg_loss :  0.07323534786701202\n",
      "entropy_loss:  1.0454915761947632\n",
      "disc_loss :  0.5377609133720398\n",
      "iter end, time :  0.9984126091003418\n",
      "train end\n",
      "epoch_time :  994.5948340892792\n",
      "global correct: 90.8\n",
      "mean correct:59.1\n",
      "mean IoU: 52.2\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 90.43608093261719  | 86.24386596679688  |\n",
      "|    Sidewalk   | 32.962642669677734 | 31.238157272338867 |\n",
      "|  Construction | 92.55799865722656  | 71.58946990966797  |\n",
      "|     Fence     |  42.6015510559082  | 33.20093536376953  |\n",
      "|      Pole     | 15.814314842224121 | 14.153471946716309 |\n",
      "| Traffic Light | 33.590431213378906 | 27.873811721801758 |\n",
      "|  Traffic Sign | 53.99671173095703  | 48.03692626953125  |\n",
      "|     Nature    | 83.48471069335938  |  78.8333740234375  |\n",
      "|      Sky      | 97.52629852294922  | 94.58251190185547  |\n",
      "|     Person    | 5.6354780197143555 | 5.527931213378906  |\n",
      "|     Rider     | 35.455997467041016 | 12.562358856201172 |\n",
      "|      Car      | 84.78023529052734  | 80.26107788085938  |\n",
      "|   Background  |  98.8341064453125  |  94.109619140625   |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.521702766418457 Best: 0.5226086378097534\n",
      "current epoch : 24\n",
      "[0.0013878515601215093, 0.013878515601215093] [5.551406240486037e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.12304578721523285\n",
      "entropy_loss:  1.0270428657531738\n",
      "disc_loss :  0.5106204748153687\n",
      "iter end, time :  0.9972991943359375\n",
      "iters :  100\n",
      "seg_loss :  0.10627789050340652\n",
      "entropy_loss:  0.9296097159385681\n",
      "disc_loss :  0.5614238977432251\n",
      "iter end, time :  1.0128538608551025\n",
      "iters :  200\n",
      "seg_loss :  0.11855652183294296\n",
      "entropy_loss:  0.9357000589370728\n",
      "disc_loss :  0.5607714056968689\n",
      "iter end, time :  1.0032744407653809\n",
      "iters :  300\n",
      "seg_loss :  0.0650327205657959\n",
      "entropy_loss:  1.1986174583435059\n",
      "disc_loss :  0.5249655842781067\n",
      "iter end, time :  1.0005192756652832\n",
      "iters :  400\n",
      "seg_loss :  0.06403358280658722\n",
      "entropy_loss:  1.1473681926727295\n",
      "disc_loss :  0.47504907846450806\n",
      "iter end, time :  1.0061182975769043\n",
      "iters :  500\n",
      "seg_loss :  0.05469200387597084\n",
      "entropy_loss:  0.868689775466919\n",
      "disc_loss :  0.48126357793807983\n",
      "iter end, time :  1.0050055980682373\n",
      "iters :  600\n",
      "seg_loss :  0.11640265583992004\n",
      "entropy_loss:  1.0667805671691895\n",
      "disc_loss :  0.6042366623878479\n",
      "iter end, time :  1.0027227401733398\n",
      "iters :  700\n",
      "seg_loss :  0.10913439840078354\n",
      "entropy_loss:  1.012499451637268\n",
      "disc_loss :  0.5556012392044067\n",
      "iter end, time :  0.9965057373046875\n",
      "iters :  800\n",
      "seg_loss :  0.08121349662542343\n",
      "entropy_loss:  1.1349884271621704\n",
      "disc_loss :  0.614589512348175\n",
      "iter end, time :  1.0198252201080322\n",
      "iters :  900\n",
      "seg_loss :  0.07674706727266312\n",
      "entropy_loss:  0.9486702680587769\n",
      "disc_loss :  0.5484151244163513\n",
      "iter end, time :  1.0123012065887451\n",
      "train end\n",
      "epoch_time :  994.3629384040833\n",
      "global correct: 90.9\n",
      "mean correct:56.3\n",
      "mean IoU: 51.3\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 89.45281982421875  | 85.89048767089844  |\n",
      "|    Sidewalk   |  38.2788200378418  | 34.88616180419922  |\n",
      "|  Construction | 92.52762603759766  |  72.1059341430664  |\n",
      "|     Fence     | 28.295330047607422 | 25.60075569152832  |\n",
      "|      Pole     | 22.12470817565918  | 18.336936950683594 |\n",
      "| Traffic Light | 34.49653244018555  | 29.22245216369629  |\n",
      "|  Traffic Sign |  51.2401123046875  | 47.06831359863281  |\n",
      "|     Nature    |  86.7334213256836  | 80.70277404785156  |\n",
      "|      Sky      | 97.27498626708984  | 94.13389587402344  |\n",
      "|     Person    | 2.341960906982422  | 2.2716565132141113 |\n",
      "|     Rider     | 1.789264440536499  | 1.7307692766189575 |\n",
      "|      Car      | 88.18916320800781  | 81.88928985595703  |\n",
      "|   Background  |  98.6621322631836  | 93.11255645751953  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5130400061607361 Best: 0.5226086378097534\n",
      "current epoch : 25\n",
      "[0.0013397168281703666, 0.013397168281703665] [5.358867312681466e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.0897812694311142\n",
      "entropy_loss:  0.956175684928894\n",
      "disc_loss :  0.5451403260231018\n",
      "iter end, time :  0.9893040657043457\n",
      "iters :  100\n",
      "seg_loss :  0.09568668901920319\n",
      "entropy_loss:  0.8850661516189575\n",
      "disc_loss :  0.5581803917884827\n",
      "iter end, time :  0.9606058597564697\n",
      "iters :  200\n",
      "seg_loss :  0.08898165822029114\n",
      "entropy_loss:  1.0961804389953613\n",
      "disc_loss :  0.5911128520965576\n",
      "iter end, time :  0.9981753826141357\n",
      "iters :  300\n",
      "seg_loss :  0.0720696747303009\n",
      "entropy_loss:  1.09159255027771\n",
      "disc_loss :  0.6256696581840515\n",
      "iter end, time :  1.0081164836883545\n",
      "iters :  400\n",
      "seg_loss :  0.07008685916662216\n",
      "entropy_loss:  0.9487300515174866\n",
      "disc_loss :  0.5242822766304016\n",
      "iter end, time :  0.9933607578277588\n",
      "iters :  500\n",
      "seg_loss :  0.08911362290382385\n",
      "entropy_loss:  1.0128200054168701\n",
      "disc_loss :  0.5148391127586365\n",
      "iter end, time :  1.0052680969238281\n",
      "iters :  600\n",
      "seg_loss :  0.09015153348445892\n",
      "entropy_loss:  1.1607162952423096\n",
      "disc_loss :  0.4496656060218811\n",
      "iter end, time :  1.0003268718719482\n",
      "iters :  700\n",
      "seg_loss :  0.10438612103462219\n",
      "entropy_loss:  1.5437276363372803\n",
      "disc_loss :  0.6538286805152893\n",
      "iter end, time :  1.005988597869873\n",
      "iters :  800\n",
      "seg_loss :  0.09291855990886688\n",
      "entropy_loss:  1.0418412685394287\n",
      "disc_loss :  0.5459936261177063\n",
      "iter end, time :  1.0085663795471191\n",
      "iters :  900\n",
      "seg_loss :  0.05043960362672806\n",
      "entropy_loss:  1.1754662990570068\n",
      "disc_loss :  0.43594494462013245\n",
      "iter end, time :  1.0080101490020752\n",
      "train end\n",
      "epoch_time :  994.5349690914154\n",
      "global correct: 91.2\n",
      "mean correct:57.2\n",
      "mean IoU: 51.9\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     |  90.6080322265625  |  86.5189208984375  |\n",
      "|    Sidewalk   | 31.90120506286621  | 30.26275634765625  |\n",
      "|  Construction | 92.43680572509766  |  72.3370132446289  |\n",
      "|     Fence     | 20.893024444580078 | 19.517452239990234 |\n",
      "|      Pole     | 25.687240600585938 | 19.408660888671875 |\n",
      "| Traffic Light | 30.841238021850586 | 26.97170639038086  |\n",
      "|  Traffic Sign | 54.33019256591797  | 47.91679763793945  |\n",
      "|     Nature    | 89.77403259277344  | 82.11331939697266  |\n",
      "|      Sky      | 97.46806335449219  | 94.57540893554688  |\n",
      "|     Person    | 1.6462839841842651 | 1.639824390411377  |\n",
      "|     Rider     | 22.514507293701172 | 16.352909088134766 |\n",
      "|      Car      | 86.97596740722656  | 81.89324951171875  |\n",
      "|   Background  | 98.48943328857422  |  94.7387924194336  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5186513662338257 Best: 0.5226086378097534\n",
      "current epoch : 26\n",
      "[0.0012913891175365326, 0.012913891175365325] [5.16555647014613e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.11631318926811218\n",
      "entropy_loss:  1.020782709121704\n",
      "disc_loss :  0.6948409676551819\n",
      "iter end, time :  1.003993272781372\n",
      "iters :  100\n",
      "seg_loss :  0.10815069824457169\n",
      "entropy_loss:  1.1465568542480469\n",
      "disc_loss :  0.5418034195899963\n",
      "iter end, time :  1.011687994003296\n",
      "iters :  200\n",
      "seg_loss :  0.13603195548057556\n",
      "entropy_loss:  1.0117831230163574\n",
      "disc_loss :  0.5729233026504517\n",
      "iter end, time :  1.005375623703003\n",
      "iters :  300\n",
      "seg_loss :  0.057374507188797\n",
      "entropy_loss:  1.1707634925842285\n",
      "disc_loss :  0.6199207305908203\n",
      "iter end, time :  0.966787576675415\n",
      "iters :  400\n",
      "seg_loss :  0.1734769493341446\n",
      "entropy_loss:  1.2233052253723145\n",
      "disc_loss :  0.5085878968238831\n",
      "iter end, time :  0.9983046054840088\n",
      "iters :  500\n",
      "seg_loss :  0.08106507360935211\n",
      "entropy_loss:  0.9239538908004761\n",
      "disc_loss :  0.634398341178894\n",
      "iter end, time :  1.0072216987609863\n",
      "iters :  600\n",
      "seg_loss :  0.09220586717128754\n",
      "entropy_loss:  1.0961604118347168\n",
      "disc_loss :  0.6105393171310425\n",
      "iter end, time :  1.0082099437713623\n",
      "iters :  700\n",
      "seg_loss :  0.10606526583433151\n",
      "entropy_loss:  0.9205536842346191\n",
      "disc_loss :  0.642754316329956\n",
      "iter end, time :  1.0006763935089111\n",
      "iters :  800\n",
      "seg_loss :  0.11738190054893494\n",
      "entropy_loss:  0.9704811573028564\n",
      "disc_loss :  0.6091097593307495\n",
      "iter end, time :  1.0067341327667236\n",
      "iters :  900\n",
      "seg_loss :  0.0715361088514328\n",
      "entropy_loss:  1.202272891998291\n",
      "disc_loss :  0.4723754823207855\n",
      "iter end, time :  0.9605445861816406\n",
      "train end\n",
      "epoch_time :  993.3909525871277\n",
      "global correct: 91.1\n",
      "mean correct:57.7\n",
      "mean IoU: 52.7\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 89.83609771728516  | 85.78706359863281  |\n",
      "|    Sidewalk   | 41.43320083618164  | 37.300960540771484 |\n",
      "|  Construction | 93.14419555664062  | 72.97512817382812  |\n",
      "|     Fence     | 29.253976821899414 |  25.1822566986084  |\n",
      "|      Pole     | 20.266284942626953 | 16.93524742126465  |\n",
      "| Traffic Light | 35.460880279541016 | 29.632484436035156 |\n",
      "|  Traffic Sign | 51.64975357055664  | 47.38185501098633  |\n",
      "|     Nature    | 88.26782989501953  |   81.91943359375   |\n",
      "|      Sky      | 97.72920227050781  | 94.38265228271484  |\n",
      "|     Person    | 6.723872661590576  | 6.180942535400391  |\n",
      "|     Rider     | 14.193548202514648 | 12.354593276977539 |\n",
      "|      Car      | 84.30536651611328  | 80.51158142089844  |\n",
      "|   Background  | 98.42218017578125  | 94.23248291015625  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5267513394355774 Best: 0.5267513394355774\n",
      "current epoch : 27\n",
      "[0.0012428595598684292, 0.01242859559868429] [4.9714382394737164e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.10255827009677887\n",
      "entropy_loss:  1.2127685546875\n",
      "disc_loss :  0.569478452205658\n",
      "iter end, time :  1.0165455341339111\n",
      "iters :  100\n",
      "seg_loss :  0.07579262554645538\n",
      "entropy_loss:  1.0727698802947998\n",
      "disc_loss :  0.5756227970123291\n",
      "iter end, time :  1.0093812942504883\n",
      "iters :  200\n",
      "seg_loss :  0.0929550752043724\n",
      "entropy_loss:  0.8226372003555298\n",
      "disc_loss :  0.556536078453064\n",
      "iter end, time :  0.9944717884063721\n",
      "iters :  300\n",
      "seg_loss :  0.11009547114372253\n",
      "entropy_loss:  1.03108811378479\n",
      "disc_loss :  0.6036107540130615\n",
      "iter end, time :  1.0026488304138184\n",
      "iters :  400\n",
      "seg_loss :  0.10473687201738358\n",
      "entropy_loss:  1.0704500675201416\n",
      "disc_loss :  0.5566051602363586\n",
      "iter end, time :  1.0178806781768799\n",
      "iters :  500\n",
      "seg_loss :  0.059813492000103\n",
      "entropy_loss:  1.1108211278915405\n",
      "disc_loss :  0.5773543119430542\n",
      "iter end, time :  0.9981982707977295\n",
      "iters :  600\n",
      "seg_loss :  0.055492814630270004\n",
      "entropy_loss:  1.0746287107467651\n",
      "disc_loss :  0.5878123044967651\n",
      "iter end, time :  1.0040035247802734\n",
      "iters :  700\n",
      "seg_loss :  0.07788382470607758\n",
      "entropy_loss:  1.2522741556167603\n",
      "disc_loss :  0.5137472152709961\n",
      "iter end, time :  0.9997372627258301\n",
      "iters :  800\n",
      "seg_loss :  0.07931091636419296\n",
      "entropy_loss:  1.140061855316162\n",
      "disc_loss :  0.5625467300415039\n",
      "iter end, time :  1.0014538764953613\n",
      "iters :  900\n",
      "seg_loss :  0.09885885566473007\n",
      "entropy_loss:  1.1313470602035522\n",
      "disc_loss :  0.5166323781013489\n",
      "iter end, time :  0.9931585788726807\n",
      "train end\n",
      "epoch_time :  994.1680862903595\n",
      "global correct: 91.6\n",
      "mean correct:58.1\n",
      "mean IoU: 53.2\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     |  91.9332504272461  | 87.67855072021484  |\n",
      "|    Sidewalk   | 39.234832763671875 | 36.726654052734375 |\n",
      "|  Construction | 92.18670654296875  | 74.30682373046875  |\n",
      "|     Fence     | 26.194664001464844 | 23.721050262451172 |\n",
      "|      Pole     | 25.44599151611328  | 21.03670883178711  |\n",
      "| Traffic Light | 28.474456787109375 | 25.68393325805664  |\n",
      "|  Traffic Sign | 54.925655364990234 | 48.93144607543945  |\n",
      "|     Nature    | 89.33305358886719  | 82.12252807617188  |\n",
      "|      Sky      | 97.38121795654297  | 94.18028259277344  |\n",
      "|     Person    | 4.317983627319336  | 4.173917770385742  |\n",
      "|     Rider     |  19.8463077545166  | 17.172592163085938 |\n",
      "|      Car      | 87.44392395019531  | 81.75585174560547  |\n",
      "|   Background  |  98.5054931640625  | 94.17544555664062  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.532050609588623 Best: 0.532050609588623\n",
      "current epoch : 28\n",
      "[0.0011941184746062621, 0.01194118474606262] [4.776473898425048e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.09793224930763245\n",
      "entropy_loss:  1.128990888595581\n",
      "disc_loss :  0.6592029333114624\n",
      "iter end, time :  1.0157530307769775\n",
      "iters :  100\n",
      "seg_loss :  0.09373587369918823\n",
      "entropy_loss:  1.0697883367538452\n",
      "disc_loss :  0.5632089376449585\n",
      "iter end, time :  0.9659097194671631\n",
      "iters :  200\n",
      "seg_loss :  0.11592980474233627\n",
      "entropy_loss:  1.1834077835083008\n",
      "disc_loss :  0.5309358835220337\n",
      "iter end, time :  0.9558167457580566\n",
      "iters :  300\n",
      "seg_loss :  0.07620331645011902\n",
      "entropy_loss:  1.0103223323822021\n",
      "disc_loss :  0.5790182948112488\n",
      "iter end, time :  0.9941730499267578\n",
      "iters :  400\n",
      "seg_loss :  0.10844425857067108\n",
      "entropy_loss:  0.9695249199867249\n",
      "disc_loss :  0.4944814145565033\n",
      "iter end, time :  1.0058765411376953\n",
      "iters :  500\n",
      "seg_loss :  0.09097742289304733\n",
      "entropy_loss:  0.9825032949447632\n",
      "disc_loss :  0.5612107515335083\n",
      "iter end, time :  0.9643678665161133\n",
      "iters :  600\n",
      "seg_loss :  0.12453360855579376\n",
      "entropy_loss:  1.0674912929534912\n",
      "disc_loss :  0.599799394607544\n",
      "iter end, time :  0.9665861129760742\n",
      "iters :  700\n",
      "seg_loss :  0.09692943841218948\n",
      "entropy_loss:  0.9554269313812256\n",
      "disc_loss :  0.5163648128509521\n",
      "iter end, time :  1.000661849975586\n",
      "iters :  800\n",
      "seg_loss :  0.07443690299987793\n",
      "entropy_loss:  1.1597282886505127\n",
      "disc_loss :  0.5353481769561768\n",
      "iter end, time :  0.9994487762451172\n",
      "iters :  900\n",
      "seg_loss :  0.09310472011566162\n",
      "entropy_loss:  1.0708943605422974\n",
      "disc_loss :  0.6040619015693665\n",
      "iter end, time :  0.9993188381195068\n",
      "train end\n",
      "epoch_time :  993.1819634437561\n",
      "global correct: 91.2\n",
      "mean correct:57.6\n",
      "mean IoU: 52.6\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 91.22074890136719  | 86.78688049316406  |\n",
      "|    Sidewalk   | 36.90327835083008  |  34.6949577331543  |\n",
      "|  Construction | 93.53898620605469  | 72.80465698242188  |\n",
      "|     Fence     | 27.207183837890625 | 24.682104110717773 |\n",
      "|      Pole     | 29.528108596801758 | 22.914026260375977 |\n",
      "| Traffic Light | 31.66227912902832  | 27.32745361328125  |\n",
      "|  Traffic Sign | 56.074214935302734 | 49.98115539550781  |\n",
      "|     Nature    | 87.02739715576172  |  81.3315200805664  |\n",
      "|      Sky      | 97.37773895263672  | 94.46694946289062  |\n",
      "|     Person    | 6.630878925323486  | 6.120824813842773  |\n",
      "|     Rider     | 7.700689792633057  | 7.090301036834717  |\n",
      "|      Car      |  85.3377685546875  | 81.27635955810547  |\n",
      "|   Background  |  98.4373779296875  | 94.10014343261719  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5258287191390991 Best: 0.532050609588623\n",
      "current epoch : 29\n",
      "[0.0011451552541288331, 0.01145155254128833] [4.580621016515332e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.11170892417430878\n",
      "entropy_loss:  1.0494364500045776\n",
      "disc_loss :  0.5581442713737488\n",
      "iter end, time :  1.003328800201416\n",
      "iters :  100\n",
      "seg_loss :  0.08736330270767212\n",
      "entropy_loss:  1.1281975507736206\n",
      "disc_loss :  0.5281939506530762\n",
      "iter end, time :  1.0040392875671387\n",
      "iters :  200\n",
      "seg_loss :  0.13887353241443634\n",
      "entropy_loss:  0.9842525720596313\n",
      "disc_loss :  0.5490460395812988\n",
      "iter end, time :  1.0036697387695312\n",
      "iters :  300\n",
      "seg_loss :  0.07237124443054199\n",
      "entropy_loss:  1.2635736465454102\n",
      "disc_loss :  0.5528743267059326\n",
      "iter end, time :  0.9519515037536621\n",
      "iters :  400\n",
      "seg_loss :  0.06476568430662155\n",
      "entropy_loss:  1.0809475183486938\n",
      "disc_loss :  0.6184999346733093\n",
      "iter end, time :  0.9943199157714844\n",
      "iters :  500\n",
      "seg_loss :  0.10226510465145111\n",
      "entropy_loss:  1.2257132530212402\n",
      "disc_loss :  0.5315712690353394\n",
      "iter end, time :  0.9947640895843506\n",
      "iters :  600\n",
      "seg_loss :  0.1014159545302391\n",
      "entropy_loss:  1.0152486562728882\n",
      "disc_loss :  0.5276932120323181\n",
      "iter end, time :  1.0047235488891602\n",
      "iters :  700\n",
      "seg_loss :  0.07669483125209808\n",
      "entropy_loss:  1.2054662704467773\n",
      "disc_loss :  0.5446289777755737\n",
      "iter end, time :  1.0052075386047363\n",
      "iters :  800\n",
      "seg_loss :  0.07901793718338013\n",
      "entropy_loss:  1.1684422492980957\n",
      "disc_loss :  0.4779309034347534\n",
      "iter end, time :  0.9662363529205322\n",
      "iters :  900\n",
      "seg_loss :  0.10699182003736496\n",
      "entropy_loss:  1.2111626863479614\n",
      "disc_loss :  0.4625687599182129\n",
      "iter end, time :  0.9655218124389648\n",
      "train end\n",
      "epoch_time :  992.965283870697\n",
      "global correct: 90.8\n",
      "mean correct:56.0\n",
      "mean IoU: 51.2\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 88.53562927246094  |  85.3592300415039  |\n",
      "|    Sidewalk   | 38.24502182006836  | 35.034507751464844 |\n",
      "|  Construction | 94.02693176269531  | 71.07920837402344  |\n",
      "|     Fence     |  19.1173095703125  | 17.67218589782715  |\n",
      "|      Pole     | 25.148128509521484 | 21.206663131713867 |\n",
      "| Traffic Light | 30.821311950683594 | 26.962560653686523 |\n",
      "|  Traffic Sign | 53.82430648803711  | 49.454708099365234 |\n",
      "|     Nature    | 88.04801940917969  | 81.62985229492188  |\n",
      "|      Sky      | 97.57099914550781  | 94.84339141845703  |\n",
      "|     Person    | 3.3031928539276123 | 3.2120957374572754 |\n",
      "|     Rider     |  6.36079216003418  | 5.939630031585693  |\n",
      "|      Car      |  83.8917007446289  | 79.94129943847656  |\n",
      "|   Background  | 98.80672454833984  |  93.7369613647461  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5123633146286011 Best: 0.532050609588623\n",
      "current epoch : 30\n",
      "[0.0010959582263852174, 0.010959582263852173] [4.38383290554087e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.06399005651473999\n",
      "entropy_loss:  1.1459674835205078\n",
      "disc_loss :  0.5748512148857117\n",
      "iter end, time :  0.9466443061828613\n",
      "iters :  100\n",
      "seg_loss :  0.05360603332519531\n",
      "entropy_loss:  0.9027373790740967\n",
      "disc_loss :  0.5566960573196411\n",
      "iter end, time :  0.9574828147888184\n",
      "iters :  200\n",
      "seg_loss :  0.054728541523218155\n",
      "entropy_loss:  1.2906020879745483\n",
      "disc_loss :  0.6024067401885986\n",
      "iter end, time :  0.9687097072601318\n",
      "iters :  300\n",
      "seg_loss :  0.07203996181488037\n",
      "entropy_loss:  0.9078572392463684\n",
      "disc_loss :  0.5481512546539307\n",
      "iter end, time :  1.0080862045288086\n",
      "iters :  400\n",
      "seg_loss :  0.09918438643217087\n",
      "entropy_loss:  1.0194547176361084\n",
      "disc_loss :  0.5486032962799072\n",
      "iter end, time :  0.9992644786834717\n",
      "iters :  500\n",
      "seg_loss :  0.12701153755187988\n",
      "entropy_loss:  1.0264794826507568\n",
      "disc_loss :  0.4891495108604431\n",
      "iter end, time :  1.0053305625915527\n",
      "iters :  600\n",
      "seg_loss :  0.0706503614783287\n",
      "entropy_loss:  0.9421218633651733\n",
      "disc_loss :  0.6044804453849792\n",
      "iter end, time :  0.989973783493042\n",
      "iters :  700\n",
      "seg_loss :  0.091183140873909\n",
      "entropy_loss:  0.9398922920227051\n",
      "disc_loss :  0.49257612228393555\n",
      "iter end, time :  1.017643690109253\n",
      "iters :  800\n",
      "seg_loss :  0.07725262641906738\n",
      "entropy_loss:  1.271172046661377\n",
      "disc_loss :  0.4960945248603821\n",
      "iter end, time :  1.0122308731079102\n",
      "iters :  900\n",
      "seg_loss :  0.08142277598381042\n",
      "entropy_loss:  1.1016442775726318\n",
      "disc_loss :  0.49786651134490967\n",
      "iter end, time :  0.9584879875183105\n",
      "train end\n",
      "epoch_time :  993.3663108348846\n",
      "global correct: 91.6\n",
      "mean correct:56.9\n",
      "mean IoU: 52.0\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 92.50713348388672  | 88.19530487060547  |\n",
      "|    Sidewalk   |  36.2630729675293  | 33.11516189575195  |\n",
      "|  Construction | 93.27743530273438  | 73.56291198730469  |\n",
      "|     Fence     | 30.409141540527344 | 26.558849334716797 |\n",
      "|      Pole     | 23.016204833984375 | 17.57419776916504  |\n",
      "| Traffic Light | 32.01702117919922  | 28.23589515686035  |\n",
      "|  Traffic Sign | 54.099727630615234 | 48.19687271118164  |\n",
      "|     Nature    | 88.42674255371094  | 81.62545776367188  |\n",
      "|      Sky      | 97.17832946777344  | 94.54728698730469  |\n",
      "|     Person    | 3.528280258178711  |  3.37455677986145  |\n",
      "|     Rider     | 6.5942301750183105 | 6.171108245849609  |\n",
      "|      Car      | 84.22149658203125  | 80.48748016357422  |\n",
      "|   Background  |  98.3985595703125  | 94.91030883789062  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5204272866249084 Best: 0.532050609588623\n",
      "current epoch : 31\n",
      "[0.0010465144892430704, 0.010465144892430703] [4.186057956972281e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.07894407212734222\n",
      "entropy_loss:  1.0580155849456787\n",
      "disc_loss :  0.5035380721092224\n",
      "iter end, time :  0.9951951503753662\n",
      "iters :  100\n",
      "seg_loss :  0.09273987263441086\n",
      "entropy_loss:  1.1036323308944702\n",
      "disc_loss :  0.4904055595397949\n",
      "iter end, time :  1.0019924640655518\n",
      "iters :  200\n",
      "seg_loss :  0.06300763040781021\n",
      "entropy_loss:  0.9676108360290527\n",
      "disc_loss :  0.6251911520957947\n",
      "iter end, time :  1.0073838233947754\n",
      "iters :  300\n",
      "seg_loss :  0.08979341387748718\n",
      "entropy_loss:  0.9166350960731506\n",
      "disc_loss :  0.5789886713027954\n",
      "iter end, time :  1.013206958770752\n",
      "iters :  400\n",
      "seg_loss :  0.1253783404827118\n",
      "entropy_loss:  1.0723470449447632\n",
      "disc_loss :  0.5780376195907593\n",
      "iter end, time :  1.0054409503936768\n",
      "iters :  500\n",
      "seg_loss :  0.07747043669223785\n",
      "entropy_loss:  1.1045308113098145\n",
      "disc_loss :  0.5566322803497314\n",
      "iter end, time :  0.9991683959960938\n",
      "iters :  600\n",
      "seg_loss :  0.09249871224164963\n",
      "entropy_loss:  1.043700933456421\n",
      "disc_loss :  0.5755023956298828\n",
      "iter end, time :  0.9915742874145508\n",
      "iters :  700\n",
      "seg_loss :  0.06888517737388611\n",
      "entropy_loss:  1.0748438835144043\n",
      "disc_loss :  0.5478360652923584\n",
      "iter end, time :  0.9875607490539551\n",
      "iters :  800\n",
      "seg_loss :  0.095211923122406\n",
      "entropy_loss:  1.1321773529052734\n",
      "disc_loss :  0.6026268005371094\n",
      "iter end, time :  0.9647178649902344\n",
      "iters :  900\n",
      "seg_loss :  0.06910164654254913\n",
      "entropy_loss:  1.1137971878051758\n",
      "disc_loss :  0.5891849994659424\n",
      "iter end, time :  0.9969654083251953\n",
      "train end\n",
      "epoch_time :  994.9514534473419\n",
      "global correct: 91.4\n",
      "mean correct:58.0\n",
      "mean IoU: 53.0\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 90.76593017578125  | 86.91254425048828  |\n",
      "|    Sidewalk   |  41.5447998046875  | 38.16036605834961  |\n",
      "|  Construction | 93.12886810302734  |  73.2660140991211  |\n",
      "|     Fence     | 29.770130157470703 | 27.11176300048828  |\n",
      "|      Pole     | 20.894041061401367 | 17.63173484802246  |\n",
      "| Traffic Light | 32.987396240234375 | 28.227270126342773 |\n",
      "|  Traffic Sign | 53.65531539916992  | 48.18836212158203  |\n",
      "|     Nature    | 89.34329986572266  | 81.66412353515625  |\n",
      "|      Sky      | 97.05675506591797  |  94.4560775756836  |\n",
      "|     Person    | 4.301388740539551  | 4.218780040740967  |\n",
      "|     Rider     | 15.331695556640625 | 13.259668350219727 |\n",
      "|      Car      |  86.3679428100586  | 81.66499328613281  |\n",
      "|   Background  | 98.40911102294922  | 94.17069244384766  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5299480557441711 Best: 0.532050609588623\n",
      "current epoch : 32\n",
      "[0.000996809708923461, 0.00996809708923461] [3.987238835693844e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.06607970595359802\n",
      "entropy_loss:  1.0967261791229248\n",
      "disc_loss :  0.6064602732658386\n",
      "iter end, time :  0.9564871788024902\n",
      "iters :  100\n",
      "seg_loss :  0.08038260787725449\n",
      "entropy_loss:  1.0437514781951904\n",
      "disc_loss :  0.5429363250732422\n",
      "iter end, time :  1.012333631515503\n",
      "iters :  200\n",
      "seg_loss :  0.10743212699890137\n",
      "entropy_loss:  1.0683026313781738\n",
      "disc_loss :  0.5356438755989075\n",
      "iter end, time :  1.002488136291504\n",
      "iters :  300\n",
      "seg_loss :  0.05114583298563957\n",
      "entropy_loss:  1.3258386850357056\n",
      "disc_loss :  0.47624629735946655\n",
      "iter end, time :  1.0076301097869873\n",
      "iters :  400\n",
      "seg_loss :  0.06200285628437996\n",
      "entropy_loss:  1.180861234664917\n",
      "disc_loss :  0.46215784549713135\n",
      "iter end, time :  1.0141501426696777\n",
      "iters :  500\n",
      "seg_loss :  0.08119559288024902\n",
      "entropy_loss:  1.0869944095611572\n",
      "disc_loss :  0.5209735631942749\n",
      "iter end, time :  1.0073513984680176\n",
      "iters :  600\n",
      "seg_loss :  0.07092268019914627\n",
      "entropy_loss:  1.2695996761322021\n",
      "disc_loss :  0.43131744861602783\n",
      "iter end, time :  0.9961178302764893\n",
      "iters :  700\n",
      "seg_loss :  0.05311700329184532\n",
      "entropy_loss:  1.028428077697754\n",
      "disc_loss :  0.5528327226638794\n",
      "iter end, time :  1.0047831535339355\n",
      "iters :  800\n",
      "seg_loss :  0.1167636513710022\n",
      "entropy_loss:  1.3996014595031738\n",
      "disc_loss :  0.591609001159668\n",
      "iter end, time :  0.9720818996429443\n",
      "iters :  900\n",
      "seg_loss :  0.073068767786026\n",
      "entropy_loss:  1.2020453214645386\n",
      "disc_loss :  0.5900763273239136\n",
      "iter end, time :  0.9565699100494385\n",
      "train end\n",
      "epoch_time :  993.3835246562958\n",
      "global correct: 91.1\n",
      "mean correct:57.8\n",
      "mean IoU: 52.7\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 90.60275268554688  | 87.00568389892578  |\n",
      "|    Sidewalk   |   38.71337890625   | 35.676246643066406 |\n",
      "|  Construction | 93.64147186279297  | 72.42732238769531  |\n",
      "|     Fence     | 21.463247299194336 | 20.15900993347168  |\n",
      "|      Pole     | 22.457351684570312 | 18.537097930908203 |\n",
      "| Traffic Light | 30.658445358276367 | 26.581836700439453 |\n",
      "|  Traffic Sign | 52.504974365234375 | 46.874168395996094 |\n",
      "|     Nature    |   88.65576171875   | 81.77800750732422  |\n",
      "|      Sky      | 97.37686920166016  | 94.49860382080078  |\n",
      "|     Person    | 6.830350875854492  | 6.519977569580078  |\n",
      "|     Rider     | 25.356124877929688 | 21.284591674804688 |\n",
      "|      Car      | 83.78277587890625  | 80.24392700195312  |\n",
      "|   Background  | 98.77044677734375  | 93.76376342773438  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5271925330162048 Best: 0.532050609588623\n",
      "current epoch : 33\n",
      "[0.0009468278722913483, 0.009468278722913483] [3.787311489165393e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.0844886377453804\n",
      "entropy_loss:  0.9987589120864868\n",
      "disc_loss :  0.6056150197982788\n",
      "iter end, time :  0.9993507862091064\n",
      "iters :  100\n",
      "seg_loss :  0.07417124509811401\n",
      "entropy_loss:  0.9917718768119812\n",
      "disc_loss :  0.5775831937789917\n",
      "iter end, time :  1.0060009956359863\n",
      "iters :  200\n",
      "seg_loss :  0.06053087115287781\n",
      "entropy_loss:  1.0712794065475464\n",
      "disc_loss :  0.6247768402099609\n",
      "iter end, time :  0.9985446929931641\n",
      "iters :  300\n",
      "seg_loss :  0.06218994781374931\n",
      "entropy_loss:  0.9487160444259644\n",
      "disc_loss :  0.5892965793609619\n",
      "iter end, time :  1.006347894668579\n",
      "iters :  400\n",
      "seg_loss :  0.06827466189861298\n",
      "entropy_loss:  1.1472673416137695\n",
      "disc_loss :  0.6338620185852051\n",
      "iter end, time :  1.0121862888336182\n",
      "iters :  500\n",
      "seg_loss :  0.05444136634469032\n",
      "entropy_loss:  1.2750928401947021\n",
      "disc_loss :  0.5279582738876343\n",
      "iter end, time :  1.0032603740692139\n",
      "iters :  600\n",
      "seg_loss :  0.051427505910396576\n",
      "entropy_loss:  0.8763734102249146\n",
      "disc_loss :  0.5510994791984558\n",
      "iter end, time :  1.0024254322052002\n",
      "iters :  700\n",
      "seg_loss :  0.0564291886985302\n",
      "entropy_loss:  1.0656840801239014\n",
      "disc_loss :  0.5499844551086426\n",
      "iter end, time :  1.017336368560791\n",
      "iters :  800\n",
      "seg_loss :  0.04762290418148041\n",
      "entropy_loss:  1.0212324857711792\n",
      "disc_loss :  0.5126211047172546\n",
      "iter end, time :  1.0045552253723145\n",
      "iters :  900\n",
      "seg_loss :  0.05073212832212448\n",
      "entropy_loss:  1.1942455768585205\n",
      "disc_loss :  0.5475060343742371\n",
      "iter end, time :  1.0121231079101562\n",
      "train end\n",
      "epoch_time :  992.7234060764313\n",
      "global correct: 90.9\n",
      "mean correct:57.1\n",
      "mean IoU: 52.1\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 89.39474487304688  | 86.11943054199219  |\n",
      "|    Sidewalk   | 38.89801025390625  | 35.918243408203125 |\n",
      "|  Construction | 94.59809112548828  | 71.05342864990234  |\n",
      "|     Fence     | 16.21332550048828  | 15.454069137573242 |\n",
      "|      Pole     | 21.621734619140625 | 17.684194564819336 |\n",
      "| Traffic Light | 30.350345611572266 | 26.169490814208984 |\n",
      "|  Traffic Sign |  53.602294921875   | 47.99257278442383  |\n",
      "|     Nature    | 88.65706634521484  |  81.7588882446289  |\n",
      "|      Sky      | 96.90263366699219  | 94.52584838867188  |\n",
      "|     Person    | 4.103036403656006  | 3.9433484077453613 |\n",
      "|     Rider     | 24.382383346557617 | 21.475875854492188 |\n",
      "|      Car      |  84.9424819946289  | 80.98371887207031  |\n",
      "|   Background  | 98.56342315673828  | 94.39371490478516  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5211329460144043 Best: 0.532050609588623\n",
      "current epoch : 34\n",
      "[0.0008965509790765194, 0.008965509790765193] [3.586203916306077e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.09347643703222275\n",
      "entropy_loss:  0.8113574981689453\n",
      "disc_loss :  0.5723411440849304\n",
      "iter end, time :  1.0112144947052002\n",
      "iters :  100\n",
      "seg_loss :  0.07630227506160736\n",
      "entropy_loss:  1.0039260387420654\n",
      "disc_loss :  0.6104791164398193\n",
      "iter end, time :  1.008763313293457\n",
      "iters :  200\n",
      "seg_loss :  0.05441168695688248\n",
      "entropy_loss:  0.926209568977356\n",
      "disc_loss :  0.5377101898193359\n",
      "iter end, time :  0.9913432598114014\n",
      "iters :  300\n",
      "seg_loss :  0.05354733765125275\n",
      "entropy_loss:  0.850485622882843\n",
      "disc_loss :  0.6612851619720459\n",
      "iter end, time :  1.0013267993927002\n",
      "iters :  400\n",
      "seg_loss :  0.0642579197883606\n",
      "entropy_loss:  1.0544215440750122\n",
      "disc_loss :  0.5305200219154358\n",
      "iter end, time :  1.0036022663116455\n",
      "iters :  500\n",
      "seg_loss :  0.06569403409957886\n",
      "entropy_loss:  0.9270520210266113\n",
      "disc_loss :  0.607347309589386\n",
      "iter end, time :  1.0024361610412598\n",
      "iters :  600\n",
      "seg_loss :  0.13541969656944275\n",
      "entropy_loss:  1.082779884338379\n",
      "disc_loss :  0.5148125290870667\n",
      "iter end, time :  1.001582384109497\n",
      "iters :  700\n",
      "seg_loss :  0.13848572969436646\n",
      "entropy_loss:  0.9580239057540894\n",
      "disc_loss :  0.5506844520568848\n",
      "iter end, time :  0.9957373142242432\n",
      "iters :  800\n",
      "seg_loss :  0.0730900913476944\n",
      "entropy_loss:  1.0443270206451416\n",
      "disc_loss :  0.47317448258399963\n",
      "iter end, time :  0.994318962097168\n",
      "iters :  900\n",
      "seg_loss :  0.03957504779100418\n",
      "entropy_loss:  1.1069309711456299\n",
      "disc_loss :  0.5275546312332153\n",
      "iter end, time :  1.008530855178833\n",
      "train end\n",
      "epoch_time :  993.2002413272858\n",
      "global correct: 90.9\n",
      "mean correct:56.2\n",
      "mean IoU: 51.4\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     | 89.96195983886719  | 86.17606353759766  |\n",
      "|    Sidewalk   | 31.435102462768555 | 29.660276412963867 |\n",
      "|  Construction | 93.78649139404297  | 71.10796356201172  |\n",
      "|     Fence     | 18.094053268432617 | 16.767229080200195 |\n",
      "|      Pole     | 24.585248947143555 | 18.692291259765625 |\n",
      "| Traffic Light | 31.293100357055664 | 27.073999404907227 |\n",
      "|  Traffic Sign | 54.431907653808594 |  49.5677375793457  |\n",
      "|     Nature    | 89.93666076660156  | 82.18791961669922  |\n",
      "|      Sky      | 97.01813507080078  | 94.46983337402344  |\n",
      "|     Person    | 1.787239670753479  | 1.744931936264038  |\n",
      "|     Rider     | 16.06922149658203  | 15.550239562988281 |\n",
      "|      Car      | 83.73202514648438  | 80.21505737304688  |\n",
      "|   Background  | 98.22242736816406  | 95.13607025146484  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5141150951385498 Best: 0.532050609588623\n",
      "current epoch : 35\n",
      "[0.0008459586547541247, 0.008459586547541247] [3.3838346190164985e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.08171330392360687\n",
      "entropy_loss:  1.0987226963043213\n",
      "disc_loss :  0.5874711275100708\n",
      "iter end, time :  0.9963550567626953\n",
      "iters :  100\n",
      "seg_loss :  0.049073826521635056\n",
      "entropy_loss:  0.9594734907150269\n",
      "disc_loss :  0.6016959547996521\n",
      "iter end, time :  0.9605607986450195\n",
      "iters :  200\n",
      "seg_loss :  0.0531008206307888\n",
      "entropy_loss:  1.05964994430542\n",
      "disc_loss :  0.6242680549621582\n",
      "iter end, time :  1.0011050701141357\n",
      "iters :  300\n",
      "seg_loss :  0.11597036570310593\n",
      "entropy_loss:  0.9856262803077698\n",
      "disc_loss :  0.4771968722343445\n",
      "iter end, time :  1.0107786655426025\n",
      "iters :  400\n",
      "seg_loss :  0.06540409475564957\n",
      "entropy_loss:  1.2084593772888184\n",
      "disc_loss :  0.49919605255126953\n",
      "iter end, time :  1.0000956058502197\n",
      "iters :  500\n",
      "seg_loss :  0.06014105677604675\n",
      "entropy_loss:  1.244589924812317\n",
      "disc_loss :  0.5270594954490662\n",
      "iter end, time :  0.9604332447052002\n",
      "iters :  600\n",
      "seg_loss :  0.053620606660842896\n",
      "entropy_loss:  1.1980260610580444\n",
      "disc_loss :  0.4485589563846588\n",
      "iter end, time :  0.9963328838348389\n",
      "iters :  700\n",
      "seg_loss :  0.06547845155000687\n",
      "entropy_loss:  1.1410596370697021\n",
      "disc_loss :  0.5639020204544067\n",
      "iter end, time :  1.0113205909729004\n",
      "iters :  800\n",
      "seg_loss :  0.10648826509714127\n",
      "entropy_loss:  1.0131484270095825\n",
      "disc_loss :  0.4666769802570343\n",
      "iter end, time :  1.0000107288360596\n",
      "iters :  900\n",
      "seg_loss :  0.06853067129850388\n",
      "entropy_loss:  0.8388957977294922\n",
      "disc_loss :  0.5662121176719666\n",
      "iter end, time :  0.9643580913543701\n",
      "train end\n",
      "epoch_time :  993.3564596176147\n",
      "global correct: 90.7\n",
      "mean correct:54.8\n",
      "mean IoU: 50.2\n",
      "+---------------+--------------------+--------------------+\n",
      "|     class     |        acc         |        iou         |\n",
      "+---------------+--------------------+--------------------+\n",
      "|      Road     |  90.1250991821289  | 86.66803741455078  |\n",
      "|    Sidewalk   | 37.99921798706055  | 34.81729507446289  |\n",
      "|  Construction | 95.01090240478516  | 70.43062591552734  |\n",
      "|     Fence     | 16.715681076049805 | 15.766697883605957 |\n",
      "|      Pole     | 19.728418350219727 | 16.167617797851562 |\n",
      "| Traffic Light | 24.69890785217285  | 22.207746505737305 |\n",
      "|  Traffic Sign | 48.987640380859375 | 45.16984176635742  |\n",
      "|     Nature    | 87.91342163085938  | 81.22111511230469  |\n",
      "|      Sky      | 96.90715026855469  | 94.74320220947266  |\n",
      "|     Person    | 1.587684988975525  | 1.5685739517211914 |\n",
      "|     Rider     | 13.718070030212402 | 12.361466407775879 |\n",
      "|      Car      | 80.49787139892578  | 77.83309173583984  |\n",
      "|   Background  | 98.60255432128906  | 94.25357818603516  |\n",
      "+---------------+--------------------+--------------------+\n",
      "Target: 0.5024684071540833 Best: 0.532050609588623\n",
      "current epoch : 36\n",
      "[0.0007950276569174988, 0.007950276569174988] [3.180110627669995e-05]\n",
      "train start\n",
      "iters :  0\n",
      "seg_loss :  0.06654287874698639\n",
      "entropy_loss:  0.981731653213501\n",
      "disc_loss :  0.6028622388839722\n",
      "iter end, time :  1.0001158714294434\n",
      "iters :  100\n",
      "seg_loss :  0.04842280596494675\n",
      "entropy_loss:  1.1664665937423706\n",
      "disc_loss :  0.594318151473999\n",
      "iter end, time :  0.9707214832305908\n",
      "iters :  200\n",
      "seg_loss :  0.07618705928325653\n",
      "entropy_loss:  1.0283021926879883\n",
      "disc_loss :  0.47647368907928467\n",
      "iter end, time :  1.000913381576538\n",
      "iters :  300\n",
      "seg_loss :  0.05990888178348541\n",
      "entropy_loss:  0.9756999611854553\n",
      "disc_loss :  0.49723684787750244\n",
      "iter end, time :  0.963031530380249\n",
      "iters :  400\n",
      "seg_loss :  0.049631789326667786\n",
      "entropy_loss:  1.1920509338378906\n",
      "disc_loss :  0.6191290616989136\n",
      "iter end, time :  0.9984896183013916\n",
      "iters :  500\n",
      "seg_loss :  0.08130298554897308\n",
      "entropy_loss:  0.9595829248428345\n",
      "disc_loss :  0.6339248418807983\n",
      "iter end, time :  1.0114014148712158\n",
      "iters :  600\n",
      "seg_loss :  0.08241653442382812\n",
      "entropy_loss:  0.9727859497070312\n",
      "disc_loss :  0.5649650692939758\n",
      "iter end, time :  0.9693155288696289\n",
      "iters :  700\n",
      "seg_loss :  0.055082354694604874\n",
      "entropy_loss:  1.0344613790512085\n",
      "disc_loss :  0.5380141735076904\n",
      "iter end, time :  1.0096173286437988\n",
      "iters :  800\n",
      "seg_loss :  0.050102729350328445\n",
      "entropy_loss:  1.0032706260681152\n",
      "disc_loss :  0.5803976058959961\n",
      "iter end, time :  1.0134837627410889\n",
      "iters :  900\n",
      "seg_loss :  0.09500278532505035\n",
      "entropy_loss:  1.1711475849151611\n",
      "disc_loss :  0.5888688564300537\n",
      "iter end, time :  1.0024354457855225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m re_checkpoint \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./save_path/model_save_v2_flow_19.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m main(re_checkpoint)\n\u001b[1;32m      3\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[17], line 97\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(resume)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m train_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 97\u001b[0m train(train_source_iter, train_target_iter, model, interp_train, criterion, dann,flownet, optimizer,\n\u001b[1;32m     98\u001b[0m       lr_scheduler, optimizer_d, lr_scheduler_d, epoch)\n\u001b[1;32m     99\u001b[0m train_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    100\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_source_iter, train_target_iter, model, interp, criterion, dann, flownet, optimizer, lr_scheduler, optimizer_d, lr_scheduler_d, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m pred_t \u001b[39m=\u001b[39m interp(y_t)\n\u001b[1;32m     56\u001b[0m loss_transfer \u001b[39m=\u001b[39m dann(pred_t, \u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# target image의 prediction 값을\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m (loss_transfer \u001b[39m*\u001b[39;49m trade_off)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     59\u001b[0m \u001b[39m# Step 2: Train the discriminator\u001b[39;00m\n\u001b[1;32m     60\u001b[0m dann\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dinov2/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "re_checkpoint = './save_path/model_save_v2_flow_19.pth'\n",
    "main(re_checkpoint)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4b226",
   "metadata": {},
   "source": [
    "##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Entropy Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e107543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_layers = [model.model.blocks[-1].norm1]\n",
    "\n",
    "# def reshape_transform(tensor, height=16, width=16):\n",
    "#     result = tensor[:, 1 :  , :].reshape(tensor.size(0),\n",
    "#         height, width, tensor.size(2))\n",
    "\n",
    "#     # Bring the channels to the first dimension,\n",
    "#     # like in CNNs.\n",
    "#     result = result.transpose(2, 3).transpose(1, 2)\n",
    "#     return result\n",
    "\n",
    "# cam = GradCAM(model=model2.model, target_layers=target_layers, reshape_transform=reshape_transform)\n",
    "\n",
    "# def analysis_image(image, target_class):\n",
    "#   img = cv2.resize(image, [224, 224])\n",
    "#   img = np.expand_dims(img, axis = 0)\n",
    "#   img = torch.FloatTensor(img).permute(0,3,1,2)\n",
    "#   input_tensor = img.cuda()\n",
    "\n",
    "#   targets = [ClassifierOutputTarget(target_class)]\n",
    "\n",
    "#   Cam = cam(input_tensor = input_tensor, targets = targets)\n",
    "\n",
    "#   img2 = cv2.resize(image, [224, 224]) / 255.\n",
    "\n",
    "#   Cam = np.expand_dims(np.squeeze(Cam, axis = 0), axis = -1)\n",
    "\n",
    "#   visualization = show_cam_on_image(img2.astype(np.float32), Cam, use_rgb = True)\n",
    "\n",
    "#   # colab에서 실행하기 때문에 cv2.imshow 대신 cv2_imshow 함수 이용\n",
    "#   cv2_imshow(visualization)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(train_size[0], train_size[1]),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "if mode == 'val':\n",
    "    test_dataset = CustomDataset(csv_file='./val_source.csv', transform=transform, infer=True)\n",
    "elif mode == 'test':\n",
    "    test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)#\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eb7759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(save_model):\n",
    "    interp_val = nn.Upsample(size=test_output_size[::-1], mode='bilinear', align_corners=True)\n",
    "    with torch.no_grad():\n",
    "        num_classes = num_class\n",
    "        model = deeplabv2_resnet101(num_classes=num_classes).to(device)\n",
    "        model.load_state_dict(save_model)\n",
    "        model.eval()\n",
    "        result = []\n",
    "        iter=0\n",
    "        batch_size=16\n",
    "        for images in tqdm(test_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = interp_val(outputs)\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "            # batch에 존재하는 각 이미지에 대해서 반복\n",
    "            for i,pred in enumerate(outputs,1):\n",
    "                mask_img = np.zeros((540,960,3),dtype=np.uint8)\n",
    "                pred = pred.astype(np.uint8)\n",
    "                pred = Image.fromarray(pred) # 이미지로 변환\n",
    "                pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "                pred = np.array(pred) # 다시 수치로 변환\n",
    "                # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "                for class_id in range(12):\n",
    "                    class_mask = (pred == class_id).astype(np.uint8)\n",
    "                    mask_img = palette[pred]\n",
    "                    # if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    #     mask_rle = rle_encode(class_mask)\n",
    "                    #     result.append(mask_rle)\n",
    "                    # else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    #     result.append(-1)\n",
    "\n",
    "                if mode == 'val':\n",
    "                    test = pd.read_csv('./val_source.csv')\n",
    "                elif mode == 'test':\n",
    "                    test = pd.read_csv('./test.csv')\n",
    "                img_name=test['id'][iter*16+i-1]\n",
    "                img_org = cv2.imread(test['img_path'][iter*16+i-1])\n",
    "                img_org = cv2.resize(img_org,(960,540))\n",
    "            \n",
    "                result = np.hstack((img_org,mask_img))\n",
    "                if mode == 'val':\n",
    "                    new_gt = np.zeros((540,960,3),dtype=np.uint8)\n",
    "                    img_gt = cv2.imread(test['gt_path'][iter*16+i-1],0)\n",
    "                    img_gt = cv2.resize(img_gt,(960,540))\n",
    "                    mask_255 = np.where(img_gt>=12)\n",
    "                    img_gt[mask_255] = 12\n",
    "                    new_gt = palette[img_gt]\n",
    "                    result = np.hstack((img_org,mask_img,new_gt))\n",
    "                    if not os.path.exists('./mask_save_s'):\n",
    "                        os.makedirs('./mask_save_s')\n",
    "                    cv2.imwrite(f\"./mask_save_s/{img_name}.png\",result)\n",
    "                elif mode == 'test':    \n",
    "                    if not os.path.exists('./mask_save'):\n",
    "                        os.makedirs('./mask_save')\n",
    "                    cv2.imwrite(f\"./mask_save/{img_name}.png\",result)\n",
    "\n",
    "            iter+=1\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeacf6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/119 [00:11<22:48, 11.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./save_path/model_save_v2_flow_27.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(model_path, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m inference(checkpoint[\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36minference\u001b[0;34m(save_model)\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[39m=\u001b[39m interp_val(outputs)\n\u001b[1;32m     15\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m---> 16\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(outputs, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m \u001b[39m# batch에 존재하는 각 이미지에 대해서 반복\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m i,pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(outputs,\u001b[39m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = './save_path/model_save_v2_flow_27.pth'\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "result = inference(checkpoint['model'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mask_rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000_class_0</td>\n",
       "      <td>453748 5 454705 10 454739 5 455663 14 455696 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0000_class_1</td>\n",
       "      <td>442379 2 443278 6 443337 5 444235 13 444267 8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0000_class_2</td>\n",
       "      <td>1 6 18 100 602 355 961 13 977 101 1561 358 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0000_class_3</td>\n",
       "      <td>496650 12 496674 8 497624 4 498583 6 499543 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0000_class_4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22771</th>\n",
       "      <td>TEST_1897_class_7</td>\n",
       "      <td>125776 1 126736 2 127695 3 128655 4 129615 4 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22772</th>\n",
       "      <td>TEST_1897_class_8</td>\n",
       "      <td>94 543 678 126 1053 543 1639 124 2012 543 2600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22773</th>\n",
       "      <td>TEST_1897_class_9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>TEST_1897_class_10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22775</th>\n",
       "      <td>TEST_1897_class_11</td>\n",
       "      <td>205019 4 205977 8 206935 12 207750 2 207893 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                           mask_rle\n",
       "0       TEST_0000_class_0  453748 5 454705 10 454739 5 455663 14 455696 1...\n",
       "1       TEST_0000_class_1  442379 2 443278 6 443337 5 444235 13 444267 8 ...\n",
       "2       TEST_0000_class_2  1 6 18 100 602 355 961 13 977 101 1561 358 192...\n",
       "3       TEST_0000_class_3  496650 12 496674 8 497624 4 498583 6 499543 6 ...\n",
       "4       TEST_0000_class_4                                                 -1\n",
       "...                   ...                                                ...\n",
       "22771   TEST_1897_class_7  125776 1 126736 2 127695 3 128655 4 129615 4 1...\n",
       "22772   TEST_1897_class_8  94 543 678 126 1053 543 1639 124 2012 543 2600...\n",
       "22773   TEST_1897_class_9                                                 -1\n",
       "22774  TEST_1897_class_10                                                 -1\n",
       "22775  TEST_1897_class_11  205019 4 205977 8 206935 12 207750 2 207893 15...\n",
       "\n",
       "[22776 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./flow19_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
